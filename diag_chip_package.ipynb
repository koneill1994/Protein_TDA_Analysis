{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import imageio\n",
    "import json\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import animation\n",
    "\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "available_cpu=multiprocessing.cpu_count()-1\n",
    "\n",
    "\n",
    "pdb_list, length_dict, input_features = np.load(\"datasets/sample-input-features.npy\",allow_pickle=True)\n",
    "pdb_list_y, distance_maps_cb = np.load(\"datasets/sample-distance-maps-cb.npy\",encoding=\"latin1\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aaron's code to get raw features from pdb\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# ! pip install biopython\n",
    "# ! pip install nglview\n",
    "# ! jupyter-nbextension enable nglview --py --sys-prefix\n",
    "\n",
    "from Bio.PDB import *\n",
    "import nglview as nv\n",
    "import math\n",
    "import warnings\n",
    "from Bio.PDB.StructureBuilder import PDBConstructionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=PDBConstructionWarning)\n",
    "\n",
    "# this is dangerous of course but uncomment it when you want to run the code\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaron's code to make sure the folders are all in their proper place\n",
    "\n",
    "dirlocal = os.path.curdir\n",
    "data_path = os.path.join(dirlocal, 'Data/')\n",
    "protein_path = os.path.join(data_path, 'Proteins/')\n",
    "pdb_path = os.path.join(data_path, 'PDB/')\n",
    "fasta_path = os.path.join(data_path, 'fasta/')\n",
    "dssp_path = os.path.join(data_path, 'DSSP/')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "if not os.path.exists(protein_path):\n",
    "    os.makedirs(protein_path)\n",
    "if not os.path.exists(pdb_path):\n",
    "    os.makedirs(pdb_path)\n",
    "ss_path = os.path.join(data_path, 'ss.txt')\n",
    "feature_path = os.path.join(data_path, 'sample-input-features.npy')\n",
    "distance_path = os.path.join(data_path, 'sample-distance-maps-cb.npy')\n",
    "full_feature_path = os.path.join(data_path, 'full-input-features.npy')\n",
    "full_distance_path = os.path.join(data_path, 'full-distance-maps-cb.npy')\n",
    "test_feature_path = os.path.join(data_path, 'testset-input-features.npy')\n",
    "test_distance_path = os.path.join(data_path, 'testset-distance-maps-cb.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  aaron's functions: \n",
    "\n",
    "# gets dataframe containing torsion angles, peptides, chain, etc\n",
    "# from pdb file\n",
    "def get_torsion_angles(pdb_id, degrees=False):\n",
    "    pdb_struct = get_pdb_structure(pdb_id)\n",
    "    torsion_angles = []\n",
    "    for model in pdb_struct:\n",
    "        for chain in model:\n",
    "            polypeptides = PPBuilder().build_peptides(chain)\n",
    "            for poly_index, poly in enumerate(polypeptides):\n",
    "                #print(\"Model %s Chain %s\" % (str(model.id), str(chain.id)))\n",
    "                #print(\"(part %i of %i)\" % (poly_index+1, len(polypeptides)))\n",
    "                #print(\"length %i\" % (len(poly)))\n",
    "                #print(\"from %s%i\" % (poly[0].resname, poly[0].id[1]))\n",
    "                #print(\"to %s%i\" % (poly[-1].resname, poly[-1].id[1]))\n",
    "                phi_psi = poly.get_phi_psi_list()\n",
    "                for res_index, residue in enumerate(poly):\n",
    "                    res_name = \"%s%i\" % (residue.resname, residue.id[1])\n",
    "                    #print(res_name, tuple(math.degrees(b) for b in phi_psi[res_index] if b))\n",
    "                    deg = phi_psi[res_index]\n",
    "                    if degrees:\n",
    "                        deg = tuple(math.degrees(b) if b else None for b in deg)\n",
    "                    phi, psi = deg\n",
    "                    model_name, model_id = model.full_id\n",
    "                    torsion_angles.append([model_name, model_id, chain.id, residue.resname, residue.id[1], phi, psi])\n",
    "    return pd.DataFrame(torsion_angles, columns=['Model_Name', 'Model_ID', 'Chain', 'Residue_Name', 'Residue_ID', 'Phi', 'Psi'])\n",
    "\n",
    "\n",
    "# generates ramachandran plot from a given pdb file\n",
    "def ramachandran_plot(pdb_id, degrees=True):\n",
    "    df = get_torsion_angles(pdb_id, degrees)\n",
    "    x = df['Phi']\n",
    "    y = df['Psi']\n",
    "    # Generate plot\n",
    "    plt.plot(x, y, \".\")\n",
    "    plt.title('Ramachandran Plot')\n",
    "    if degrees:\n",
    "        plt.xlabel(f'$\\Phi$ Angle (Degrees)')\n",
    "        plt.xlim(-180, 180)\n",
    "        plt.ylabel(f'$\\Psi$ Angle (Radians)')\n",
    "        plt.ylim(-180, 180)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.xlabel(f'$\\Phi$ Angle (Radians)')\n",
    "        plt.xlim(-math.pi, math.pi)\n",
    "        plt.ylabel(f'$\\Psi$ Angle (Radians)')\n",
    "        plt.ylim(-math.pi, math.pi)\n",
    "        plt.show()\n",
    "\n",
    "# helper function which generates a biopython structure\n",
    "# for display in display_protein()\n",
    "def get_pdb_structure(pdb_id):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    parser = PDBParser()\n",
    "    file_path = os.path.join(pdb_path, f\"{pdb_id}.pdb\")\n",
    "    try:\n",
    "        struct = parser.get_structure(pdb_id, file_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return struct\n",
    "\n",
    "\n",
    "#  downloads the protein in question from pdb\n",
    "def get_pdb_file(pdb_id):\n",
    "    if pdb_id+\".pdb\" in os.listdir(pdb_path):\n",
    "        return True\n",
    "\n",
    "    pdb_id = pdb_id.upper()\n",
    "    parser = PDBParser()\n",
    "    url = f'https://files.rcsb.org/download/{pdb_id}.pdb'\n",
    "    #print(url)\n",
    "    resp = requests.get(url)\n",
    "    try:\n",
    "        file_path = os.path.join(pdb_path, f'{pdb_id}.pdb')\n",
    "        if os.path.isfile(file_path) and not replace:\n",
    "            return True\n",
    "        #print(file_path)\n",
    "        file = open(file_path, \"wb\")\n",
    "        file.write(resp.content)\n",
    "        file.close()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# neato 3d viewer of a protein's structure\n",
    "def display_protein(pdb_id):\n",
    "    pdb_struct = get_pdb_structure(pdb_id)\n",
    "    view = nv.show_biopython(pdb_struct)\n",
    "    return view\n",
    "\n",
    "\n",
    "#  returns a dataframe with secondary structure, amino acid code, chain id, etc\n",
    "# deprecated\n",
    "def get_secondary_structure(pdb_id):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    indexes = get_pdb_ss_seq(pdb_id)\n",
    "    chain_df = []\n",
    "    for i, chain_ss in enumerate(indexes):\n",
    "        chain_id, seq, ss = chain_ss\n",
    "        #unknown_list = [i for i, c in enumerate(seq) if c == 'X']\n",
    "        #print(unknown_list)\n",
    "        seq_list = [c for c in seq]\n",
    "        # [f(x) if condition else g(x) for x in sequence]\n",
    "        ss_list = ['L' if c is ' ' else c for c in ss]\n",
    "        #print(seq_list + ss_list)\n",
    "        chain_df.append(pd.DataFrame({'Chain': chain_id, 'Amino_Acid':seq_list, 'Secondary_Structure':ss_list}))\n",
    "    return pd.concat(chain_df)\n",
    "\n",
    "# get matrix of pairwise carbon beta distances\n",
    "def get_cb_distances(full_pdb_id, partial=False):\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    pdb_struct = get_pdb_structure(pdb_id)  # Returns the BioPython structure of the PDB file\n",
    "    ppb = PPBuilder()\n",
    "    chain_dist_matrix = {}\n",
    "    for model in pdb_struct:\n",
    "        for chain in model:\n",
    "            residues = []\n",
    "            for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                for residue in pp:\n",
    "                    residues.append(residue)\n",
    "            lng = len(residues)\n",
    "            dist_matrix = np.zeros((lng, lng), np.float)\n",
    "            for i in range(0, lng):\n",
    "                for j in range(i, lng):\n",
    "                    try:\n",
    "                        diff_vector  = residues[i]['C'].coord - residues[j]['C'].coord\n",
    "                    except Exception:\n",
    "                        count = 0\n",
    "                        sums = 0\n",
    "                        if j - 1 >= 0:\n",
    "                            count += 1\n",
    "                            sums += chain_dist_matrix[i][j - 1]\n",
    "                        if i - 1 >= 0:\n",
    "                            count += 1\n",
    "                            sums += chain_dist_matrix[i - 1][j]\n",
    "                        if count > 0:\n",
    "                            diff_vector = sums / count\n",
    "                        else:\n",
    "                            diff_vector = 0\n",
    "                    dist = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "                    dist_matrix[i][j] = dist\n",
    "                    dist_matrix[j][i] = dist\n",
    "                chain_dist_matrix[chain.id] = dist_matrix\n",
    "        \n",
    "    seq_bool = get_seq_alignment(full_pdb_id)\n",
    "    if partial:    \n",
    "        seq_bool = get_seq_alignment(full_pdb_id)\n",
    "        dist_matrix = chain_dist_matrix[full_pdb_id[4].upper()]\n",
    "        return pd.DataFrame(dist_matrix[seq_bool]).iloc[:, seq_bool]\n",
    "    else:\n",
    "        return chain_dist_matrix\n",
    "\n",
    "# gets alignment of given sequence on top of the original sequence\n",
    "# from a fasta file downloaded from the cloud repository\n",
    "def get_seq_alignment(full_pdb_id):\n",
    "    seq = ''\n",
    "    for record in SeqIO.parse(os.path.join(fasta_path, f'{full_pdb_id}.fasta'), \"fasta\"):\n",
    "        seq = record.seq\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    #print(pdb_id)\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    for model in struct:\n",
    "        for chain in model:\n",
    "            if chain.id == full_pdb_id[4]:\n",
    "                ground_seq = ''\n",
    "                for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                    ground_seq += pp.get_sequence()\n",
    "                alignments = pairwise2.align.globalxx(ground_seq, str(seq))\n",
    "                al_seq = alignments[0][1]\n",
    "                al_seq_bool = [False if a is '-' else True for a in al_seq]\n",
    "                return al_seq_bool\n",
    "\n",
    "# calls dssp api to get dssp file\n",
    "def pdb_id_to_dssp_file(pdb_id, replace=False):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    rest_url = 'http://www.cmbi.umcn.nl/xssp/'\n",
    "    # Read the pdb id data into a variable\n",
    "    data = {'data': pdb_id}\n",
    "\n",
    "    # Send a request to the server to create hssp data from the pdb file data.\n",
    "    # If an error occurs, an exception is raised and the program exits. If the\n",
    "    # request is successful, the id of the job running on the server is\n",
    "    # returned.\n",
    "    url_create = f'{rest_url}api/create/pdb_id/dssp/'\n",
    "    r = requests.post(url_create, data=data)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    job_id = json.loads(r.text)['id']\n",
    "    #print(f'Job submitted successfully. Id is: {job_id}')\n",
    "\n",
    "    # Loop until the job running on the server has finished, either successfully\n",
    "    # or due to an error.\n",
    "    ready = False\n",
    "    while not ready:\n",
    "        # Check the status of the running job. If an error occurs an exception\n",
    "        # is raised and the program exits. If the request is successful, the\n",
    "        # status is returned.\n",
    "        url_status = f'{rest_url}api/status/pdb_id/dssp/{job_id}/'\n",
    "        r = requests.get(url_status)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        status = json.loads(r.text)['status']\n",
    "        #print(f'Job status is: {status}')\n",
    "\n",
    "        # If the status equals SUCCESS, exit out of the loop by changing the\n",
    "        # condition ready. This causes the code to drop into the `else` block\n",
    "        # below.\n",
    "        #\n",
    "        # If the status equals either FAILURE or REVOKED, an exception is raised\n",
    "        # containing the error message. The program exits.\n",
    "        #\n",
    "        # Otherwise, wait for five seconds and start at the beginning of the\n",
    "        # loop again.\n",
    "        if status == 'SUCCESS':\n",
    "            ready = True\n",
    "        elif status in ['FAILURE', 'REVOKED']:\n",
    "            raise Exception(json.loads(r.text)['message'])\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        # Requests the result of the job. If an error occurs an exception is\n",
    "        # raised and the program exits. If the request is successful, the result\n",
    "        # is returned.\n",
    "        url_result = f'{rest_url}api/result/pdb_id/dssp/{job_id}/'\n",
    "        r = requests.get(url_result)\n",
    "        r.raise_for_status()\n",
    "        result = json.loads(r.text)['result']\n",
    "        try:\n",
    "            file_path = os.path.join(dssp_path, f'{pdb_id}.dssp')\n",
    "            if os.path.isfile(file_path) and not replace:\n",
    "                return True\n",
    "            #print(file_path)\n",
    "            file = open(file_path, \"w\")\n",
    "            file.write(result)\n",
    "            file.close()\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            return False\n",
    "        # Return the result to the caller, which prints it to the screen.\n",
    "        return True\n",
    "\n",
    "# uses api call file to generate secondary structure, phi/psi, solvent-accessibility stuff\n",
    "# because of indexing stuff, it crashes if we use partial = True\n",
    "# ask aaron about that\n",
    "def get_ground_truth_api(full_pdb_id, partial=False):\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    struct_info = []\n",
    "    seq_count = 0\n",
    "    for model in struct:\n",
    "        file = os.path.join(pdb_path, f'{pdb_id}.pdb')\n",
    "        pdb_id_to_dssp_file(pdb_id)\n",
    "        dssp = DSSP(model=model, in_file=os.path.join(dssp_path, f'{pdb_id}.dssp'), file_type='DSSP')\n",
    "        #dssp = DSSP(model=model, in_file=file)\n",
    "        for i, chain in enumerate(model):\n",
    "            for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                seq = pp.get_sequence()\n",
    "                for j, residue in enumerate(pp):\n",
    "                    #print(residue.id[1], seq[i])\n",
    "                    #print(dssp.keys()[j % (i + 1)])\n",
    "                    key = list(dssp.keys())[seq_count]\n",
    "                    seq_count += 1\n",
    "                    dssp_info = dssp[key]\n",
    "                    #print(dssp_info)\n",
    "                    #dssp_id = dssp_info[0]\n",
    "                    amino_acid = dssp_info[1]\n",
    "                    sec_struct = dssp_info[2]\n",
    "                    solv_acc = dssp_info[3]\n",
    "                    phi = dssp_info[4]\n",
    "                    psi = dssp_info[5]\n",
    "                    # Keys 6 through 13 is bonding energy / relidx (no clue what this is)\n",
    "                    #print(dssp[dssp.keys()[i]])\n",
    "                    struct_info.append([model.full_id[0], model.full_id[1], chain.id,\n",
    "                    residue.resname, residue.id[1], amino_acid, sec_struct, solv_acc, phi, psi])\n",
    "    info_df = pd.DataFrame(struct_info, \n",
    "        columns=['Model_Name', 'Model_ID', 'Chain', 'Residue_Name',\n",
    "        'Residue_ID', 'Amino_Acid', 'Secondary_Structure', 'Solvent_Accessability', \n",
    "        'Phi', 'Psi'])\n",
    "    if partial:    \n",
    "        seq_bool = get_seq_alignment(full_pdb_id)\n",
    "        fin_df = info_df[info_df['Chain'] == full_pdb_id[4].upper()]\n",
    "        return fin_df[seq_bool]\n",
    "    else:\n",
    "        return info_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates the secondary structure ground truth proportions\n",
    "# for a protein in a certain range(start,stop) of amino acids\n",
    "\n",
    "def ss_ground_truth(protein_id, aa_range,secs):\n",
    "    sstructs=\"HBEGITS\"\n",
    "\n",
    "    k=secs[secs['Chain']==protein_id[4]]\n",
    "    k=k.iloc[aa_range,:]\n",
    "\n",
    "    ss_count=[]\n",
    "\n",
    "    for ss in sstructs:\n",
    "        ss_count.append(len(k[k['Secondary_Structure']==ss])/len(k))\n",
    "\n",
    "    return ss_count\n",
    "\n",
    "# H = alpha helix\n",
    "# B = residue in isolated beta-bridge\n",
    "# E = extended strand, participates in beta ladder\n",
    "# G = 3-helix (3/10 helix)\n",
    "# I = 5 helix (pi helix)\n",
    "# T = hydrogen bonded turn\n",
    "# S = bend\n",
    "\n",
    "\n",
    "# DON'T USE THIS\n",
    "# its too intensive to call it over and over again\n",
    "def format_torsion_angles_to_dataframe(pdb_id, start, chip_size):\n",
    "    \n",
    "    get_pdb_file(pdb_id)\n",
    "    \n",
    "    angles=[]\n",
    "    ta=get_torsion_angles(pdb_id)\n",
    "\n",
    "    angles+=list(ta.iloc[start:start+chip_size,:][\"Phi\"])\n",
    "    angles+=list(ta.iloc[start:start+chip_size,:][\"Psi\"])\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def get_torsion_for_df(pdb_id):\n",
    "    get_pdb_file(pdb_id)\n",
    "    return get_torsion_angles(pdb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "\n",
    "# mean function\n",
    "# just for utility purposes\n",
    "def mean(numlist):\n",
    "    return sum(numlist)/len(numlist)\n",
    "\n",
    "# this creates triangular chips along (but not including)\n",
    "# the diagonal within the comparison matrix\n",
    "def chip_diagonal(chip_size, step_size, aa_length):\n",
    "    tri=[]\n",
    "    for diag in range(0,aa_length-chip_size,step_size):\n",
    "        tri.append(\n",
    "            [(y,x) for y in range(diag,diag+chip_size) for x in range(y+1,chip_size+diag+1)]\n",
    "        )\n",
    "        # NB: y already has diag added to it\n",
    "    return tri\n",
    "\n",
    "\n",
    "# create a gif showing where the triangular chipping window is located\n",
    "def gif_from_tri(protein_id,tri,filename):\n",
    "    \n",
    "    protein = np.array(distance_maps_cb[protein_id])\n",
    "    l=len(protein)\n",
    "\n",
    "    gif=[]\n",
    "\n",
    "    for t in tri:\n",
    "        new_test=np.ones((l,l))*0\n",
    "        for (y,x) in t:\n",
    "            new_test[y,x]=protein[y,x]\n",
    "\n",
    "        im=plt.imshow(new_test)\n",
    "\n",
    "        x=im.make_image(\"AGG\")[0]\n",
    "        x=np.flipud(x)\n",
    "\n",
    "        gif.append(np.array(x))\n",
    "\n",
    "    imageio.mimsave(filename+'.gif', gif, fps=5)\n",
    "\n",
    "\n",
    "# create a dataframe from a given protein id, chip size, and step size\n",
    "def diag_chips_to_df(protein_id, chip_size, step_size):\n",
    "    \n",
    "    # arrange all the feature matrices into proper form so we can \n",
    "    # reference them properly later\n",
    "    \n",
    "    chain_id=protein_id[4]\n",
    "    \n",
    "    protein_dist = np.array(get_cb_distances(protein_id)[chain_id])\n",
    "    aa_length=len(protein_dist[0])\n",
    "    \n",
    "    protein_feat = np.array(input_features[protein_id])\n",
    "\n",
    "    feat_len=len(protein_feat[0])\n",
    "    pad_len=aa_length-feat_len\n",
    "    \n",
    "    ccmpred=protein_feat[5].astype(np.float)\n",
    "    ccmpred.shape=(feat_len,feat_len)\n",
    "    ccmpred=np.pad(ccmpred,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    freecontact=protein_feat[6].astype(np.float)\n",
    "    freecontact.shape=(feat_len,feat_len)\n",
    "    freecontact=np.pad(freecontact,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    pstat_pots=protein_feat[7].astype(np.float)\n",
    "    pstat_pots.shape=(feat_len,feat_len)\n",
    "    pstat_pots=np.pad(pstat_pots,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    chips=chip_diagonal(chip_size, step_size, aa_length)\n",
    "    \n",
    "#     print(protein_id)\n",
    "    \n",
    "    gt=get_ground_truth_api(protein_id,partial=False) # set to inverse\n",
    "    gt_chain=gt[gt['Chain']==chain_id]\n",
    "    \n",
    "    # create column labels\n",
    "    cols=[\"protein_id\",\"chip_id\"]\n",
    "    cols+=[\"start\",\"stop\"]\n",
    "    cols+=[\"dist_\"+str(n) for n in range(0,len(chips[0]))]\n",
    "    cols+=[\"psipred_helix\",\"psipred_sheet\",\"psipred_coil\"]\n",
    "    cols+=[\"psisolv\",\"shannon_entropy\"]\n",
    "    cols+=[\"ccmpred\",\"freecontact\",\"pstat_pots\"]\n",
    "    cols+=[\"ground_truth_\"+x for x in \"HBEGITS\"]\n",
    "    cols+=[\"phi_\"+str(x) for x in range(0,chip_size)]\n",
    "    cols+=[\"psi_\"+str(x) for x in range(0,chip_size)]\n",
    "\n",
    "    \n",
    "    chiplist=[]\n",
    "    \n",
    "    t_phi=list(gt_chain['Phi'])\n",
    "    t_psi=list(gt_chain['Psi'])\n",
    "    \n",
    "    # loop through all the chips\n",
    "    for i in range(0,len(chips)):\n",
    "        \n",
    "        # row identifiers\n",
    "        row=[protein_id,\"chip_\"+str(i)]\n",
    "        row+=[i,i+chip_size]\n",
    "        \n",
    "        # inclusion range\n",
    "        # between the first amino acid being compared \n",
    "        # and the last amino acid being compared\n",
    "        # NB this assumes that \n",
    "        incl_range=range(min(min(chips[i])),max(max(chips[i])))\n",
    "        \n",
    "        # 1d features\n",
    "        base_helix=protein_feat[0].astype(np.float)\n",
    "        base_sheet=protein_feat[1].astype(np.float)\n",
    "        base_coil=protein_feat[2].astype(np.float)\n",
    "        base_solv=protein_feat[3].astype(np.float)\n",
    "        base_shan=protein_feat[4].astype(np.float)\n",
    "        \n",
    "        base_helix=np.pad(base_helix,pad_len,'constant', constant_values=(0))\n",
    "        base_sheet=np.pad(base_sheet,pad_len,'constant', constant_values=(0))\n",
    "        base_coil=np.pad(base_coil,pad_len,'constant', constant_values=(0))\n",
    "        base_solv=np.pad(base_solv,pad_len,'constant', constant_values=(0))\n",
    "        base_shan=np.pad(base_shan,pad_len,'constant', constant_values=(0))\n",
    "        \n",
    "        psipred_helix=mean(base_helix[incl_range])\n",
    "        psipred_sheet=mean(base_sheet[incl_range])\n",
    "        psipred_coil=mean(base_coil[incl_range])\n",
    "        psisolv=mean(base_solv[incl_range])\n",
    "        shannon_entropy=mean(base_shan[incl_range])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2d features\n",
    "        ccmpred_pool=[]\n",
    "        freecontact_pool=[]\n",
    "        pstat_pool=[]\n",
    "        \n",
    "        # ss ground truth\n",
    "        ssgt=ss_ground_truth(protein_id,incl_range,gt_chain)\n",
    "        \n",
    "        # loop through each pixel in the chip\n",
    "        for n in range(0,len(chips[i])):\n",
    "            \n",
    "#             make sure we're not on the diagonal\n",
    "#             print([chips[i][n][0],chips[i][n][1]])\n",
    "            \n",
    "            row.append(\n",
    "                protein_dist[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            ccmpred_pool.append(\n",
    "                ccmpred[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            freecontact_pool.append(\n",
    "                freecontact[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            pstat_pool.append(\n",
    "                pstat_pots[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            \n",
    "        # 1d features\n",
    "        row.append(psipred_helix)\n",
    "        row.append(psipred_sheet)\n",
    "        row.append(psipred_coil)\n",
    "        row.append(psisolv)\n",
    "        row.append(shannon_entropy)\n",
    "   \n",
    "        # 2d features\n",
    "        row.append(max(ccmpred_pool))\n",
    "        row.append(max(freecontact_pool))\n",
    "        row.append(max(pstat_pool))\n",
    "        \n",
    "        # ground truth\n",
    "        [row.append(x) for x in ssgt]\n",
    "        \n",
    "        # torsional angles\n",
    "        row+=t_phi[i:i+chip_size]\n",
    "        row+=t_psi[i:i+chip_size]\n",
    "        \n",
    "#         print(row)\n",
    "        \n",
    "        # add to df\n",
    "        chiplist.append(row)\n",
    "\n",
    "#     AssertionError: 94 columns passed, passed data had 75 columns\n",
    "# almost correct number of columns, but torsion angles not being passed correctly?\n",
    "    chip_df=pandas.DataFrame(chiplist,columns=cols)\n",
    "\n",
    "    return chip_df\n",
    "\n",
    "\n",
    "# compute the ground truth secondary structure\n",
    "# of which the majority of amino acids in a window\n",
    "# are a part of\n",
    "# i.e. that whose percentage within the window is above 50%\n",
    "def compute_majority_ss(df):\n",
    "    for ss in \"HBEGITS\":\n",
    "        df[\"maj_\"+ss]=df['ground_truth_'+ss]>.5\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some variable sizes\n",
    "\n",
    "chip_size=10\n",
    "step_size=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate the gif function\n",
    "\n",
    "# gif_from_tri(\"1hzfA0\",chip_diagonal(50,1,256),\"chiptri_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n",
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n",
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-019975e68784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mavailable_cpu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchip_parallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdb_list_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"parallel completed in \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcompute_majority_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    229\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-019975e68784>\u001b[0m in \u001b[0;36mchip_parallel\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchip_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdiag_chips_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-127-a616b09aab1d>\u001b[0m in \u001b[0;36mdiag_chips_to_df\u001b[1;34m(protein_id, chip_size, step_size)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m#     print(protein_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mgt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_ground_truth_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotein_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set to inverse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mgt_chain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Chain'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-992515eec6e9>\u001b[0m in \u001b[0;36mget_ground_truth_api\u001b[1;34m(full_pdb_id, partial)\u001b[0m\n\u001b[0;32m    267\u001b[0m                     \u001b[1;31m#print(residue.id[1], seq[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                     \u001b[1;31m#print(dssp.keys()[j % (i + 1)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdssp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m                     \u001b[0mseq_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                     \u001b[0mdssp_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdssp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# demonstrate how to create a dataset from it\n",
    "\n",
    "def chip_parallel(x):\n",
    "    return diag_chips_to_df(x,10,1)\n",
    "\n",
    "start_time=time.clock()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=available_cpu) as executor:\n",
    "    dataset=pandas.concat(executor.map(chip_parallel, pdb_list_y[0:20]))\n",
    "print(\"parallel completed in \"+ str(time.clock()-start_time))\n",
    "compute_majority_ss(dataset)\n",
    "\n",
    "dataset\n",
    "dataset.to_csv(\"datasets/protein_test_torsion.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n",
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n",
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n"
     ]
    }
   ],
   "source": [
    "dataset=pandas.concat([(diag_chips_to_df(pid,10,1)) for pid in pdb_list_y[0:10]])\n",
    "# df=diag_chips_to_df(pdb_list_y[0],10,1)\n",
    "\n",
    "# get_torsion_for_df(pdb_list_y[0][0:4])\n",
    "# gt=get_ground_truth_api(\"1b33N0\"[0:4])\n",
    "\n",
    "# gt_chain=gt[gt['Chain']==\"1b33N0\"[4]]\n",
    "\n",
    "# aa_range=list(range(240,250))\n",
    "\n",
    "# sstructs=\"HBEGITS\"\n",
    "\n",
    "# k=gt_chain[gt_chain['Chain']==pdb_list_y[0][4]]\n",
    "# k=k.iloc[aa_range,:]\n",
    "\n",
    "# ss_count=[]\n",
    "\n",
    "# for ss in sstructs:\n",
    "#     ss_count.append(len(k[k['Secondary_Structure']==ss])/len(k))\n",
    "\n",
    "# ss_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['protein_id', 'chip_id', 'start', 'stop', 'dist_0', 'dist_1', 'dist_2',\n",
       "       'dist_3', 'dist_4', 'dist_5', 'dist_6', 'dist_7', 'dist_8', 'dist_9',\n",
       "       'dist_10', 'dist_11', 'dist_12', 'dist_13', 'dist_14', 'dist_15',\n",
       "       'dist_16', 'dist_17', 'dist_18', 'dist_19', 'dist_20', 'dist_21',\n",
       "       'dist_22', 'dist_23', 'dist_24', 'dist_25', 'dist_26', 'dist_27',\n",
       "       'dist_28', 'dist_29', 'dist_30', 'dist_31', 'dist_32', 'dist_33',\n",
       "       'dist_34', 'dist_35', 'dist_36', 'dist_37', 'dist_38', 'dist_39',\n",
       "       'dist_40', 'dist_41', 'dist_42', 'dist_43', 'dist_44', 'dist_45',\n",
       "       'dist_46', 'dist_47', 'dist_48', 'dist_49', 'dist_50', 'dist_51',\n",
       "       'dist_52', 'dist_53', 'dist_54', 'psipred_helix', 'psipred_sheet',\n",
       "       'psipred_coil', 'psisolv', 'shannon_entropy', 'ccmpred', 'freecontact',\n",
       "       'pstat_pots', 'ground_truth_H', 'ground_truth_B', 'ground_truth_E',\n",
       "       'ground_truth_G', 'ground_truth_I', 'ground_truth_T', 'ground_truth_S',\n",
       "       'phi_0', 'phi_1', 'phi_2', 'phi_3', 'phi_4', 'phi_5', 'phi_6', 'phi_7',\n",
       "       'phi_8', 'phi_9', 'psi_0', 'psi_1', 'psi_2', 'psi_3', 'psi_4', 'psi_5',\n",
       "       'psi_6', 'psi_7', 'psi_8', 'psi_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_ground_truth_api(pdb_list_y[0][0:4])\n",
    "dataset.columns\n",
    "\n",
    "# pdb_list_y\n",
    "# df.to_csv(\"datasets/protein_dssp_api.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will add majority secondary structure to the dataframe\n",
    "# through loading it from file\n",
    "# i've dummied it out through the if statement but its still usefull\n",
    "if False:\n",
    "    dataset=pandas.read_csv(\"datasets/protein_full_gt.csv\")\n",
    "\n",
    "    compute_majority_ss(dataset)\n",
    "    dataset.to_csv(\"datasets/protein_full_gt_classed.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these generate triangular numbers from a row number\n",
    "# and row numbers from a triangular number\n",
    "# not sure if I use them anymore but here they are\n",
    "def tri_num(x):\n",
    "    return x*(x+1)/2\n",
    "    \n",
    "def inv_tri_num(x):\n",
    "    for i in range(0,x):\n",
    "        if tri_num(i)>x:\n",
    "            return None\n",
    "        if tri_num(i)==x:\n",
    "            return i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this draws a gif from a number of chips l\n",
    "# which will iterate through the rows of a datafile\n",
    "# and make each row (and the chip represented by that row)\n",
    "# into a frame of the gif\n",
    "def gif_from_chips(dataset,l,filename):    \n",
    "\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "    \n",
    "    gif=[]\n",
    "\n",
    "    for n in range(0,l):\n",
    "        \n",
    "        chpx=list(df.iloc[n,:])\n",
    "\n",
    "        chip_l=inv_tri_num(ncol)+1\n",
    "        chp_im=np.zeros((chip_l,chip_l))\n",
    "        triu=np.triu_indices(chip_l,1)\n",
    "        tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "\n",
    "        for i in range(0,len(tri_ind)):\n",
    "             chp_im[tri_ind[i][0],tri_ind[i][1]]=chpx[i]\n",
    "\n",
    "        im=plt.imshow(chp_im)    \n",
    "\n",
    "        \n",
    "        x=im.make_image(\"AGG\")[0]\n",
    "        x=np.flipud(x)\n",
    "\n",
    "        gif.append(np.array(x))\n",
    "\n",
    "    imageio.mimsave(filename+'.gif', gif, fps=60)\n",
    "\n",
    "    \n",
    "    \n",
    "# this is a function which will draw the average chip\n",
    "# of a dataset\n",
    "# i.e. draw a chip whose pixels are each an average of the\n",
    "# pixels in that position on each chip\n",
    "def draw_avg_chip(dataset, name, max_dist):\n",
    "    \n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "#     print(ncol)\n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.zeros((chip_l,chip_l))\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    for i in range(0,len(tri_ind)):\n",
    "         chp_im[tri_ind[i][0],tri_ind[i][1]]=chpx[i]\n",
    "\n",
    "    im=plt.imshow(chp_im,vmax=max_dist)\n",
    "    \n",
    "    x=im.make_image(\"AGG\")[0]\n",
    "    x=np.flipud(x)\n",
    "    \n",
    "    imageio.imsave(\"plots/\"+name+\".png\", x)\n",
    "    \n",
    "# as above, but draws a lineplot instead of a chip\n",
    "def draw_avg_dist_lineplot(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(tri_ind)):\n",
    "         chp_im[tri_ind[i][0],tri_ind[i][1]-tri_ind[i][0]]=chpx[i]\n",
    "\n",
    "    plt.ylim((0, max_dist))\n",
    "    plt.plot(np.nanmean(chp_im,0))\n",
    "    \n",
    "    plt.savefig(\"plots/lineg/\"+name+\".png\")\n",
    "    plt.cla()\n",
    "\n",
    "# as above, but draws a densityplot instead of a lineplot\n",
    "def draw_avg_dist_densityplot(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "    \n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    seq_dist=[triu[1][i]-triu[0][i] for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    cx=[]\n",
    "    cy=[]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(0,len(seq_dist)):\n",
    "            cx.append(seq_dist[i])\n",
    "            cy.append(row[i])\n",
    "\n",
    "    plt.ylim((0, max_dist))\n",
    "\n",
    "    plt.hist2d(cx,cy)\n",
    " \n",
    "    plt.savefig(\"plots/2dhist/\"+name+\".png\")\n",
    "    plt.cla()\n",
    "    \n",
    "    \n",
    "    # as above, but draws a densityplot which does not have an\n",
    "    # artificially brightened area for lower amino acid sequence distances\n",
    "    # because we average across sequence distance per chip\n",
    "    # before averaging across chips\n",
    "def draw_avg_dist_densityplot2(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "        \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    cx=[]\n",
    "    cy=[]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(0,chip_l):\n",
    "            chp_im[tri_ind[i][0],tri_ind[i][1]-tri_ind[i][0]]=row[i]\n",
    "        \n",
    "        cx+=(list(range(1,chip_l)))\n",
    "        cy+=list(np.nanmean(chp_im,0))[1:]\n",
    "\n",
    "    xbins=np.linspace(1,chip_l,chip_l)\n",
    "    ybins=np.linspace(1,max_dist,chip_l*2)\n",
    "    \n",
    "\n",
    "    plt.hist2d(cx,cy,bins = (xbins,ybins))\n",
    " \n",
    "    plt.savefig(\"plots/2dhist/\"+name+\".png\")\n",
    "    \n",
    "def get_avg_distances(dataset):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    return(list(df.mean(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_api(full_pdb_id, partial=False):\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    struct_info = []\n",
    "    seq_count = 0\n",
    "    for model in struct:\n",
    "        file = os.path.join(pdb_path, f'{pdb_id}.pdb')\n",
    "        pdb_id_to_dssp_file(pdb_id)\n",
    "        dssp = DSSP(model=model, in_file=os.path.join(dssp_path, f'{pdb_id}.dssp'), file_type='DSSP')\n",
    "        #dssp = DSSP(model=model, in_file=file)\n",
    "        for i, chain in enumerate(model):\n",
    "            for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                seq = pp.get_sequence()\n",
    "                for j, residue in enumerate(pp):\n",
    "                    #print(residue.id[1], seq[i])\n",
    "                    #print(dssp.keys()[j % (i + 1)])\n",
    "                    key = list(dssp.keys())[seq_count]\n",
    "                    seq_count += 1\n",
    "                    dssp_info = dssp[key]\n",
    "                    #print(dssp_info)\n",
    "                    #dssp_id = dssp_info[0]\n",
    "                    amino_acid = dssp_info[1]\n",
    "                    sec_struct = dssp_info[2]\n",
    "                    solv_acc = dssp_info[3]\n",
    "                    phi = dssp_info[4]\n",
    "                    psi = dssp_info[5]\n",
    "                    # Keys 6 through 13 is bonding energy / relidx (no clue what this is)\n",
    "                    #print(dssp[dssp.keys()[i]])\n",
    "                    struct_info.append([model.full_id[0], model.full_id[1], chain.id,\n",
    "                    residue.resname, residue.id[1], amino_acid, sec_struct, solv_acc, phi, psi])\n",
    "    info_df = pd.DataFrame(struct_info, \n",
    "        columns=['Model_Name', 'Model_ID', 'Chain', 'Residue_Name',\n",
    "        'Residue_ID', 'Amino_Acid', 'Secondary_Structure', 'Solvent_Accessability', \n",
    "        'Phi', 'Psi'])\n",
    "    if partial:    \n",
    "        seq_bool = get_seq_alignment(full_pdb_id)\n",
    "        fin_df = info_df[info_df['Chain'] == full_pdb_id[4].upper()]\n",
    "        return fin_df[seq_bool]\n",
    "    else:\n",
    "        return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset=pandas.read_csv(\"datasets/protein_test_gt.csv\")\n",
    "\n",
    "\n",
    "draw_avg_dist_densityplot2(dataset.iloc[0:100,:],\"test\",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate the gif_from_chips function\n",
    "# which draws an animated gif of a number of chips from a saved dataset\n",
    "\n",
    "# gif_from_chips(dataset,500,\"chip_draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this draws the avg distance for each pixel in all chips\n",
    "# within each point in a thd dendrogram\n",
    "\n",
    "def draw_thd_segmentations(folder,prefix,dataset):\n",
    "    tda_dir=\"datasets/\"+folder\n",
    "\n",
    "    thds=[n for n in os.listdir(tda_dir) if n[0:len(prefix)]==prefix]\n",
    "        \n",
    "    df_list=[]\n",
    "    names=[]\n",
    "    maxes=[]\n",
    "    \n",
    "    for model in thds:\n",
    "        \n",
    "        with open(tda_dir+model) as jsonf:\n",
    "            a=json.load(jsonf)\n",
    "            \n",
    "            df=dataset.iloc[[int(m) for m in a['rowList']],:]\n",
    "            \n",
    "#             print(model)\n",
    "#             print([int(m) for m in a['rowList']])\n",
    "            \n",
    "            maxes.append(max(get_avg_distances(df)))\n",
    "            df_list.append(df)\n",
    "            names.append(model[len(prefix):len(model)-5])\n",
    "            \n",
    "    max_dist=max(maxes)\n",
    "    for i in range(0,len(df_list)):\n",
    "#         draw_avg_chip(df_list[i],names[i],max_dist)\n",
    "#         draw_avg_dist_lineplot(df_list[i],names[i],max_dist)\n",
    "#         draw_avg_dist_densityplot(df_list[i],names[i],max_dist)\n",
    "        draw_avg_dist_densityplot2(df_list[i],names[i],max_dist)\n",
    "\n",
    "def thd_row_lengths(folder,prefix):\n",
    "    tda_dir=\"datasets/\"+folder\n",
    "\n",
    "    thds=[n for n in os.listdir(tda_dir) if n[0:len(prefix)]==prefix]\n",
    "    \n",
    "    d={}\n",
    "    \n",
    "    for model in thds:\n",
    "        \n",
    "        with open(tda_dir+model) as jsonf:\n",
    "            a=json.load(jsonf)\n",
    "\n",
    "            d[model]=a['meta']['row_count']\n",
    "    \n",
    "    for i in d:\n",
    "        print(i +\" \"+ str(round(d[i]/max(d.values()),2)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demonstrate draw_thd_segmentations\n",
    "\n",
    "# read in the dataset to use below\n",
    "# dataset=pandas.read_csv(\"datasets/protein_test_gt.csv\")\n",
    "\n",
    "\n",
    "#     draw_thd_segmentations(\"thd_test__Absolute Correlation_protein_test_gt_majority.csv_2019.06.18 15.51.08/\",\"thd_test_ \",dataset)\n",
    "# thd_row_lengths(\"thd_test__Absolute Correlation_protein_test_gt_majority.csv_2019.06.18 15.51.08/\",\"thd_test_ \")\n",
    "\n",
    "#     draw_thd_segmentations(\"THD_test_Absolute Correlation_protein_test_fifteen_gt.csv_2019.06.19 14.20.55/\",\"THD_test \",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screwing around with showing secondary structures in chart\n",
    "def twod_secondary_struct(pdb_id):\n",
    "    dim=length_dict[pdb_id]\n",
    "    k=distance_maps_cb[pdb_id].astype(float).reshape(dim,dim)\n",
    "\n",
    "    plt.imshow(np.triu(k))\n",
    "    plt.show()\n",
    "\n",
    "    helix=np.matrix(input_features[pdb_id][0].astype(float))\n",
    "    k=np.repeat(helix,dim,0)\n",
    "\n",
    "    plt.imshow(np.triu(np.transpose(k)*k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(chip_diagonal(10, 1, 278)[267]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
