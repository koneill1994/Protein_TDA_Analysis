{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/badriadhikari/IEEE-ICMLA-2019-PIDP-Challenge/blob/master/PIDP_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9805
    },
    "colab_type": "code",
    "id": "QHaZWhgHFoBW",
    "outputId": "ae6522b2-9cc3-41c1-a2e7-914f52ade62c"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ef623ffd21d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "# 4-6-2019\n",
    "# Badri Adhikari\n",
    "# https://badriadhikari.github.io/\n",
    "################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "import keras.backend as K\n",
    "epsilon = K.epsilon()\n",
    "from io import BytesIO, StringIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import argparse\n",
    "\n",
    "################################################################################\n",
    "flag_show_plots = True # True for Notebooks, False otherwise\n",
    "if flag_show_plots:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.pyplot import figure\n",
    "\n",
    "################################################################################\n",
    "dirlocal = './dataset/'\n",
    "dirgcp = 'gs://protein-distance/'\n",
    "dataset = 'sample' # 'sample' or 'full'\n",
    "stamp = datetime.datetime.now().strftime('%m_%d_%Y_%H_%M_%S_%f')\n",
    "modelfile = 'model-' + str(stamp) + '.h5'\n",
    "max_epochs = 64\n",
    "es_patience = 32\n",
    "if dataset == 'sample':\n",
    "    max_epochs = 8\n",
    "    es_patience = 1\n",
    "\n",
    "################################################################################\n",
    "def determine_number_of_channels(input_features, pdb_list, length_dict):\n",
    "    F = 0\n",
    "    x = input_features[pdb_list[0]]\n",
    "    l = length_dict[pdb_list[0]]\n",
    "    for feature in x:\n",
    "        if len(feature) == l:\n",
    "            F += 2\n",
    "        elif len(feature) == l * l:\n",
    "            F += 1\n",
    "        else:\n",
    "            print('Expecting features to be either L or L*L !! Something went wrong!!', l, len(feature))\n",
    "            sys.exit(1)\n",
    "    return F\n",
    "\n",
    "################################################################################\n",
    "def print_max_avg_sum_of_each_channel(x):\n",
    "    print(' Channel        Avg        Max        Sum')\n",
    "    for i in range(len(x[0, 0, :])):\n",
    "        (m, s, a) = (x[:, :, i].flatten().max(), x[:, :, i].flatten().sum(), x[:, :, i].flatten().mean())\n",
    "        print(' %7s %10.4f %10.4f %10.1f' % (i, a, m, s))\n",
    "\n",
    "################################################################################\n",
    "# Roll out 1D features to two 2D features, all to 256 x 256 (because many are smaller)\n",
    "def prepare_input_features_2D(pdbs, input_features, distance_maps_cb, length_dict, F):\n",
    "    X = np.full((len(pdbs), 256, 256, F), 0.0)\n",
    "    Y = np.full((len(pdbs), 256, 256, 1), 100.0)\n",
    "    for i, pdb in enumerate(pdbs):\n",
    "        x = input_features[pdb]\n",
    "        y = distance_maps_cb[pdb]\n",
    "        l = length_dict[pdb]\n",
    "        newi = 0\n",
    "        xmini = np.zeros((l, l, F))\n",
    "        for feature in x:\n",
    "            feature = np.array(feature)\n",
    "            feature = feature.astype(np.float)\n",
    "            if len(feature) == l:\n",
    "                for k in range(0, l):\n",
    "                    xmini[k, :, newi] = feature\n",
    "                    xmini[:, k, newi + 1] = feature\n",
    "                newi += 2\n",
    "            elif len(feature) == l * l:\n",
    "                xmini[:, :, newi] = feature.reshape(l, l)\n",
    "                newi += 1\n",
    "            else:\n",
    "                print('Expecting features to be either L or L*L !! Something went wrong!!', l, len(feature))\n",
    "                sys.exit(1)\n",
    "        if l > 256:\n",
    "            l = 256\n",
    "        X[i, 0:l, 0:l, :] = xmini[:l, :l, :]\n",
    "        Y[i, 0:l, 0:l, 0] = y[:l, :l]\n",
    "    return X, Y\n",
    "\n",
    "################################################################################\n",
    "def plot_input_output_of_this_protein(X, Y):\n",
    "    figure(num=None, figsize=(16, 16), dpi=80, facecolor='w', frameon=True, edgecolor='k')\n",
    "    for i in range(13):\n",
    "        plt.subplot(7, 7, i + 1)\n",
    "        plt.grid(None)\n",
    "        plt.imshow(X[:, :, i], cmap='RdYlBu', interpolation='nearest')\n",
    "    # Last plot is the true distance map\n",
    "    plt.subplot(7, 7, 14)\n",
    "    plt.grid(None)\n",
    "    plt.imshow(Y[:, :], cmap='Spectral', interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "################################################################################\n",
    "def calculate_mae(PRED, YTRUE, pdb_list, length_dict):\n",
    "    plot_count = 0\n",
    "    if flag_show_plots:\n",
    "        plot_count = 4\n",
    "    avg_mae = 0.0\n",
    "    for i in range(0, len(PRED[:, 0, 0, 0])):\n",
    "        L = length_dict[pdb_list[i]]\n",
    "        P = np.zeros((L, L))\n",
    "        # Average the predictions from both triangles (optional)\n",
    "        # This can improve MAE by upto 6% reduction\n",
    "        for j in range(0, L):\n",
    "            for k in range(0, L):\n",
    "                P[k, j] = (PRED[i, k, j, 0] + PRED[i, j, k, 0]) / 2.0\n",
    "        Y = np.copy(YTRUE[i, 0:L, 0:L, 0])\n",
    "        for j in range(0, L):\n",
    "            for k in range(0, L):\n",
    "                if k - j < 24:\n",
    "                    P[j, k] = np.inf\n",
    "                    Y[j, k] = np.inf\n",
    "        p_dict = {}\n",
    "        y_dict = {}\n",
    "        for j in range(0, L):\n",
    "            for k in range(0, L):\n",
    "                p_dict[(j,k)] = P[j, k]\n",
    "                y_dict[(j,k)] = Y[j, k]\n",
    "        top_pairs = []\n",
    "        x = L\n",
    "        for pair in sorted(p_dict.items(), key=lambda x: x[1]):\n",
    "            (k, v) = pair\n",
    "            top_pairs.append(k)\n",
    "            x -= 1\n",
    "            if x == 0:\n",
    "                break\n",
    "        sum_mae = 0.0\n",
    "        for pair in top_pairs:\n",
    "            abs_dist = abs(y_dict[pair] - p_dict[pair])\n",
    "            sum_mae += abs_dist\n",
    "        sum_mae /= L\n",
    "        avg_mae += sum_mae\n",
    "        print('MAE for ' + str(i) + ' - ' + str(pdb_list[i]) + ' = %.2f' % sum_mae)\n",
    "        if plot_count > 0:\n",
    "            plot_count -= 1\n",
    "            for j in range(0, L):\n",
    "                for k in range(0, L):\n",
    "                    if not (j, k) in top_pairs:\n",
    "                        P[j, k] = np.inf\n",
    "                        Y[j, k] = np.inf\n",
    "            for j in range(0, L):\n",
    "                for k in range(j, L):\n",
    "                    P[k, j] = Y[j, k]\n",
    "            plt.grid(None)\n",
    "            plt.imshow(P, cmap='RdYlBu', interpolation='nearest')\n",
    "            plt.show()\n",
    "    print('Average MAE = %.2f' % (avg_mae / len(PRED[:, 0, 0, 0])))\n",
    "\n",
    "################################################################################\n",
    "def main(job_dir):\n",
    "    print('job_dir = ', job_dir)\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Load input features..')\n",
    "    x = dirlocal + dataset + '-input-features.npy'\n",
    "    if not os.path.isfile(x):\n",
    "        x = BytesIO(file_io.read_file_to_string(dirgcp + dataset + '-input-features.npy', binary_mode=True))\n",
    "    (pdb_list, length_dict, input_features) = np.load(x, encoding='latin1')\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Load distance maps..')\n",
    "    x = dirlocal + dataset + '-distance-maps-cb.npy'\n",
    "    if not os.path.isfile(x):\n",
    "        x = BytesIO(file_io.read_file_to_string(dirgcp + dataset + '-distance-maps-cb.npy', binary_mode=True))\n",
    "    (pdb_list_y, distance_maps_cb) = np.load(x, encoding='latin1')\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print ('Some cross checks on data loading..')\n",
    "    for pdb in pdb_list:\n",
    "        if not pdb in pdb_list_y:\n",
    "            print ('I/O mismatch ', pdb)\n",
    "            sys.exit(1)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Find the number of input channels..')\n",
    "    F = determine_number_of_channels(input_features, pdb_list, length_dict)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Split into training and validation set (4%)..')\n",
    "    split = int(0.04 * len(pdb_list))\n",
    "    valid_pdbs = pdb_list[:split]\n",
    "    train_pdbs = pdb_list[split:]\n",
    "\n",
    "    print('Total validation proteins = ', len(valid_pdbs))\n",
    "    print('Total training proteins = ', len(train_pdbs))\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print ('Prepare the validation input and outputs..')\n",
    "    XVALID, YVALID = prepare_input_features_2D(valid_pdbs, input_features, distance_maps_cb, length_dict, F)\n",
    "    print(XVALID.shape)\n",
    "    print(YVALID.shape)\n",
    "\n",
    "    print('')\n",
    "    print ('Prepare the training input and outputs..')\n",
    "    XTRAIN, YTRAIN = prepare_input_features_2D(train_pdbs, input_features, distance_maps_cb, length_dict, F)\n",
    "    print(XTRAIN.shape)\n",
    "    print(YTRAIN.shape)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Sanity check input features values..')\n",
    "    print(' First validation protein:')\n",
    "    print_max_avg_sum_of_each_channel(XVALID[0, :, :, :])\n",
    "    print(' First traininig protein:')\n",
    "    print_max_avg_sum_of_each_channel(XTRAIN[0, :, :, :])\n",
    "\n",
    "    ################################################################################\n",
    "    if flag_show_plots:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.pyplot import figure\n",
    "        for i in range(4):\n",
    "            print('')\n",
    "            L = length_dict[valid_pdbs[i]]\n",
    "            plot_input_output_of_this_protein(XVALID[i, 0:L, 0:L, :], YVALID[i, 0:L, 0:L, 0])\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Build a model..')\n",
    "    input = Input(shape = (256, 256, F))\n",
    "    tower = BatchNormalization()(input)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(64, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    tower = Convolution2D(1, 3, padding = 'same')(tower)\n",
    "    tower = Activation('relu')(tower)\n",
    "    model = Model(input, tower)\n",
    "\n",
    "    ################################################################################\n",
    "    model.compile(loss = 'mse', optimizer = 'rmsprop', metrics = ['mae'])\n",
    "    print (model.summary())\n",
    "\n",
    "    ################################################################################\n",
    "    # a simple early stopping\n",
    "    mc = ModelCheckpoint(modelfile, monitor = 'val_mean_absolute_error', mode = 'min', verbose = 1, save_best_only = True)\n",
    "    es = EarlyStopping(monitor = 'val_mean_absolute_error', mode = 'min', verbose = 1, patience = es_patience)\n",
    "    print('')\n",
    "    print('Train the model..')\n",
    "    global max_epochs\n",
    "    history = model.fit(XTRAIN, YTRAIN, verbose = 2, batch_size = 2, epochs = max_epochs, validation_data=(XVALID, YVALID), callbacks=[es, mc])\n",
    "\n",
    "    if job_dir.startswith('gs'):\n",
    "        print ('')\n",
    "        print ('Save model weights on to google storage..')\n",
    "        with file_io.FileIO(modelfile, mode='r') as input_f:\n",
    "            with file_io.FileIO(job_dir + modelfile, mode = 'w+') as output_f:\n",
    "                output_f.write(input_f.read())\n",
    "        print('Saved best weights to ' + job_dir + modelfile)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Cuves..')\n",
    "    if flag_show_plots:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.pyplot import figure\n",
    "        print(history.params)\n",
    "        plt.clf()\n",
    "        plt.plot(history.history['mean_absolute_error'], 'g', label='Training MAE')\n",
    "        plt.plot(history.history['val_mean_absolute_error'], 'b', label='Validation MAE')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Load the best weights..')\n",
    "    model = load_model(modelfile, compile = False)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Make predictions..')\n",
    "    P = model.predict(XVALID)\n",
    "    print('')\n",
    "    print('Compare the predictions with the truths (for some proteins) ..')\n",
    "    if flag_show_plots:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.pyplot import figure\n",
    "        figure(num=None, figsize=(16, 16), dpi=80, facecolor='w', frameon=True, edgecolor='k')\n",
    "        I = 1\n",
    "        for k in range(4):\n",
    "            L = length_dict[pdb_list[k]]\n",
    "            plt.subplot(4, 4, I)\n",
    "            I += 1\n",
    "            plt.grid(None)\n",
    "            plt.imshow(P[k, 0:L, 0:L, 0], cmap='RdYlBu', interpolation='nearest')\n",
    "        for k in range(4):\n",
    "            L = length_dict[pdb_list[k]]\n",
    "            plt.subplot(4, 4, I)\n",
    "            I += 1\n",
    "            plt.grid(None)\n",
    "            plt.imshow(YVALID[k, 0:L, 0:L, 0], cmap='Spectral', interpolation='nearest')\n",
    "        plt.show()\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('MAE of top L long-range distance predictions on the validation set..')\n",
    "    calculate_mae(P, YVALID, valid_pdbs, length_dict)\n",
    "\n",
    "    ################################################################################\n",
    "    print('')\n",
    "    print('Evaluate on the test dataset..')\n",
    "    model = load_model(modelfile, compile = False)\n",
    "    x = dirlocal + 'testset-input-features.npy'\n",
    "    if not os.path.isfile(x):\n",
    "        x = BytesIO(file_io.read_file_to_string(dirgcp + 'testset-input-features.npy', binary_mode=True))\n",
    "    (pdb_list, length_dict, sequence_dict, input_features)  = np.load(x)\n",
    "    x = dirlocal + 'testset-distance-maps-cb.npy'\n",
    "    if not os.path.isfile(x):\n",
    "        x = BytesIO(file_io.read_file_to_string(dirgcp + 'testset-distance-maps-cb.npy', binary_mode=True))\n",
    "    (pdb_list_y, distance_maps_cb) = np.load(x)\n",
    "    F = determine_number_of_channels(input_features, pdb_list, length_dict)\n",
    "    XTEST, YTEST = prepare_input_features_2D(pdb_list, input_features, distance_maps_cb, length_dict, F)\n",
    "    P = model.predict(XTEST)\n",
    "    for pdb in length_dict:\n",
    "        if length_dict[pdb] > 256:\n",
    "            length_dict[pdb] = 256\n",
    "    print('')\n",
    "    print('MAE of top L long-range distance predictions on the test set..')\n",
    "    calculate_mae(P, YTEST, pdb_list, length_dict)\n",
    "\n",
    "################################################################################\n",
    "main('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m67FkbEoB4vX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "PIDP_v1.1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
