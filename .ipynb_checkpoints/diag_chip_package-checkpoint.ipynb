{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import imageio\n",
    "import json\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import animation\n",
    "\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "available_cpu=multiprocessing.cpu_count()-1\n",
    "\n",
    "\n",
    "pdb_list, length_dict, input_features = np.load(\"datasets/full-input-features.npy\",allow_pickle=True)\n",
    "pdb_list_y, distance_maps_cb = np.load(\"datasets/full-distance-maps-cb.npy\",encoding=\"latin1\",allow_pickle=True)\n",
    "\n",
    "# these proteins are obsolete (i.e. no longer in the pdb), or just otherwise weird \n",
    "# in a dumb way, so we're just gonna remove them\n",
    "\n",
    "ignore_list=[\"4osnA0\"]\n",
    "\n",
    "# ignore_list=[\"1vtz70\", \n",
    "#              \"2cmzA0\",\n",
    "#              '3vdoB0',\n",
    "#             '3zdkA0',\n",
    "#             '4bjwB0',\n",
    "#             '4bkhA0',\n",
    "#             '4h1bA0',\n",
    "#             '4hrzA0',\n",
    "#             '4i4m60',\n",
    "#             '4lu2A0',       \n",
    "#             '4rb5C0',\n",
    "#             '4rb5E0',\n",
    "#             '4rb5J0',\n",
    "#             '4rb5N0',\n",
    "#             '4rb5O0',\n",
    "#             '4rb5P0',\n",
    "#             '4rb5T0',\n",
    "#             '4rb610',\n",
    "#             '4rb620',\n",
    "#             '4rb640',\n",
    "#             '4rb680',\n",
    "#             '4rb6G0',\n",
    "#             '4rb6H0',\n",
    "#             '4rb6I0',\n",
    "#             '4rb6U0',\n",
    "#             '4rb6V0',\n",
    "#             '4rb6X0',\n",
    "#             '5a41A0',\n",
    "#             '5ajeA0',\n",
    "#             \"1jniA0\",\n",
    "#             '1vchA0',\n",
    "#             '1vkbA0',\n",
    "#             '2vqpA0',\n",
    "#             '4osnA0',\n",
    "#             '5by8A0',\n",
    "#             '4osnA0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aaron's code to get raw features from pdb\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# ! pip install biopython\n",
    "# ! pip install nglview\n",
    "# ! jupyter-nbextension enable nglview --py --sys-prefix\n",
    "\n",
    "from Bio.PDB import *\n",
    "import nglview as nv\n",
    "import math\n",
    "import warnings\n",
    "from Bio.PDB.StructureBuilder import PDBConstructionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=PDBConstructionWarning)\n",
    "\n",
    "# this is dangerous of course but uncomment it when you want to run the code\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaron's code to make sure the folders are all in their proper place\n",
    "\n",
    "dirlocal = os.path.curdir\n",
    "data_path = os.path.join(dirlocal, 'Data/')\n",
    "protein_path = os.path.join(data_path, 'Proteins/')\n",
    "pdb_path = os.path.join(data_path, 'PDB/')\n",
    "fasta_path = os.path.join(data_path, 'fasta/')\n",
    "dssp_path = os.path.join(data_path, 'DSSP/')\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "if not os.path.exists(protein_path):\n",
    "    os.makedirs(protein_path)\n",
    "if not os.path.exists(pdb_path):\n",
    "    os.makedirs(pdb_path)\n",
    "ss_path = os.path.join(data_path, 'ss.txt')\n",
    "feature_path = os.path.join(data_path, 'sample-input-features.npy')\n",
    "distance_path = os.path.join(data_path, 'sample-distance-maps-cb.npy')\n",
    "full_feature_path = os.path.join(data_path, 'full-input-features.npy')\n",
    "full_distance_path = os.path.join(data_path, 'full-distance-maps-cb.npy')\n",
    "test_feature_path = os.path.join(data_path, 'testset-input-features.npy')\n",
    "test_distance_path = os.path.join(data_path, 'testset-distance-maps-cb.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  aaron's functions: \n",
    "\n",
    "# gets dataframe containing torsion angles, peptides, chain, etc\n",
    "# from pdb file\n",
    "def get_torsion_angles(pdb_id, degrees=False):\n",
    "    pdb_struct = get_pdb_structure(pdb_id)\n",
    "    torsion_angles = []\n",
    "    for model in pdb_struct:\n",
    "        for chain in model:\n",
    "            polypeptides = PPBuilder().build_peptides(chain)\n",
    "            for poly_index, poly in enumerate(polypeptides):\n",
    "                #print(\"Model %s Chain %s\" % (str(model.id), str(chain.id)))\n",
    "                #print(\"(part %i of %i)\" % (poly_index+1, len(polypeptides)))\n",
    "                #print(\"length %i\" % (len(poly)))\n",
    "                #print(\"from %s%i\" % (poly[0].resname, poly[0].id[1]))\n",
    "                #print(\"to %s%i\" % (poly[-1].resname, poly[-1].id[1]))\n",
    "                phi_psi = poly.get_phi_psi_list()\n",
    "                for res_index, residue in enumerate(poly):\n",
    "                    res_name = \"%s%i\" % (residue.resname, residue.id[1])\n",
    "                    #print(res_name, tuple(math.degrees(b) for b in phi_psi[res_index] if b))\n",
    "                    deg = phi_psi[res_index]\n",
    "                    if degrees:\n",
    "                        deg = tuple(math.degrees(b) if b else None for b in deg)\n",
    "                    phi, psi = deg\n",
    "                    model_name, model_id = model.full_id\n",
    "                    torsion_angles.append([model_name, model_id, chain.id, residue.resname, residue.id[1], phi, psi])\n",
    "    return pd.DataFrame(torsion_angles, columns=['Model_Name', 'Model_ID', 'Chain', 'Residue_Name', 'Residue_ID', 'Phi', 'Psi'])\n",
    "\n",
    "\n",
    "# generates ramachandran plot from a given pdb file\n",
    "def ramachandran_plot(pdb_id, degrees=True):\n",
    "    df = get_torsion_angles(pdb_id, degrees)\n",
    "    x = df['Phi']\n",
    "    y = df['Psi']\n",
    "    # Generate plot\n",
    "    plt.plot(x, y, \".\")\n",
    "    plt.title('Ramachandran Plot')\n",
    "    if degrees:\n",
    "        plt.xlabel(f'$\\Phi$ Angle (Degrees)')\n",
    "        plt.xlim(-180, 180)\n",
    "        plt.ylabel(f'$\\Psi$ Angle (Radians)')\n",
    "        plt.ylim(-180, 180)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.xlabel(f'$\\Phi$ Angle (Radians)')\n",
    "        plt.xlim(-math.pi, math.pi)\n",
    "        plt.ylabel(f'$\\Psi$ Angle (Radians)')\n",
    "        plt.ylim(-math.pi, math.pi)\n",
    "        plt.show()\n",
    "\n",
    "# helper function which generates a biopython structure\n",
    "# for display in display_protein()\n",
    "def get_pdb_structure(pdb_id):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    parser = PDBParser()\n",
    "    file_path = os.path.join(pdb_path, f\"{pdb_id}.pdb\")\n",
    "    try:\n",
    "        struct = parser.get_structure(pdb_id, file_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return struct\n",
    "\n",
    "\n",
    "#  downloads the protein in question from pdb\n",
    "def get_pdb_file(pdb_id, replace=False):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    file_path = os.path.join(pdb_path, f'{pdb_id}.pdb')\n",
    "    if os.path.isfile(file_path) and not replace:\n",
    "        return True\n",
    "    parser = PDBParser()\n",
    "    url = f'https://files.rcsb.org/download/{pdb_id}.pdb'\n",
    "    resp = requests.get(url)\n",
    "    try:\n",
    "        #print(file_path)\n",
    "        file = open(file_path, \"wb\")\n",
    "        file.write(resp.content)\n",
    "        file.close()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# neato 3d viewer of a protein's structure\n",
    "def display_protein(pdb_id):\n",
    "    pdb_struct = get_pdb_structure(pdb_id)\n",
    "    view = nv.show_biopython(pdb_struct)\n",
    "    return view\n",
    "\n",
    "\n",
    "#  returns a dataframe with secondary structure, amino acid code, chain id, etc\n",
    "# deprecated\n",
    "def get_secondary_structure(pdb_id):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    indexes = get_pdb_ss_seq(pdb_id)\n",
    "    chain_df = []\n",
    "    for i, chain_ss in enumerate(indexes):\n",
    "        chain_id, seq, ss = chain_ss\n",
    "        #unknown_list = [i for i, c in enumerate(seq) if c == 'X']\n",
    "        #print(unknown_list)\n",
    "        seq_list = [c for c in seq]\n",
    "        # [f(x) if condition else g(x) for x in sequence]\n",
    "        ss_list = ['L' if c is ' ' else c for c in ss]\n",
    "        #print(seq_list + ss_list)\n",
    "        chain_df.append(pd.DataFrame({'Chain': chain_id, 'Amino_Acid':seq_list, 'Secondary_Structure':ss_list}))\n",
    "    return pd.concat(chain_df)\n",
    "\n",
    "# get matrix of pairwise carbon beta distances\n",
    "def get_cb_distances(full_pdb_id, partial=False):\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    pdb_struct = get_pdb_structure(pdb_id)  # Returns the BioPython structure of the PDB file\n",
    "    ppb = PPBuilder()\n",
    "    chain_dist_matrix = {}\n",
    "    for model in pdb_struct:\n",
    "        for chain in model:\n",
    "            if chain.id == full_pdb_id[4] and partial:\n",
    "                residues = []\n",
    "                for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                    for residue in pp:\n",
    "                        residues.append(residue)\n",
    "                lng = len(residues)\n",
    "                dist_matrix = np.zeros((lng, lng), np.float)\n",
    "                for i in range(0, lng):\n",
    "                    for j in range(i, lng):\n",
    "                        try:\n",
    "                            diff_vector  = residues[i]['C'].coord - residues[j]['C'].coord\n",
    "                        except Exception:\n",
    "                            # This just gets the average value around the unknown residue distance\n",
    "                            count = 0\n",
    "                            sums = 0\n",
    "                            if j - 1 > 0:\n",
    "                                count += 1\n",
    "                                sums += dist_matrix[i][j - 1]\n",
    "                            if i - 1 > 0:\n",
    "                                count += 1\n",
    "                                sums += dist_matrix[i - 1][j]\n",
    "                            if count > 0:\n",
    "                                diff_vector = sums / count\n",
    "                            else:\n",
    "                                diff_vector = 0\n",
    "                        dist = np.sqrt(np.sum(diff_vector * diff_vector))\n",
    "                        dist_matrix[i][j] = dist\n",
    "                        dist_matrix[j][i] = dist\n",
    "                    chain_dist_matrix = dist_matrix\n",
    "        \n",
    "    if partial:\n",
    "        start_pos, end_pos, bool_arr = get_seq_pos(full_pdb_id)\n",
    "        if start_pos == -1:\n",
    "            return pd.DataFrame(chain_dist_matrix[bool_arr]).iloc[:, bool_arr]\n",
    "        return pd.DataFrame(chain_dist_matrix[start_pos:end_pos]).iloc[:, start_pos:end_pos]\n",
    "    else:\n",
    "        return chain_dist_matrix\n",
    "    \n",
    "    \n",
    "# gets alignment of given sequence on top of the original sequence\n",
    "# from a fasta file downloaded from the cloud repository\n",
    "def get_seq_alignment(full_pdb_id):\n",
    "    seq = ''\n",
    "    for record in SeqIO.parse(os.path.join(fasta_path, f'{full_pdb_id}.fasta'), \"fasta\"):\n",
    "        seq = record.seq\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    #print(pdb_id)\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    for model in struct:\n",
    "        for chain in model:\n",
    "            if chain.id == full_pdb_id[4]:\n",
    "                ground_seq = ''\n",
    "                for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                    ground_seq += pp.get_sequence()\n",
    "                alignments = pairwise2.align.globalxx(ground_seq, str(seq))\n",
    "                al_seq = alignments[0][1]\n",
    "                al_seq_bool = [False if a is '-' else True for a in al_seq]\n",
    "                return al_seq_bool\n",
    "\n",
    "            \n",
    "def get_seq_pos(full_pdb_id):\n",
    "    seq = ''\n",
    "    for record in SeqIO.parse(os.path.join(fasta_path, f'{full_pdb_id}.fasta'), \"fasta\"):\n",
    "        seq = str(record.seq)\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    for model in struct:\n",
    "        for chain in model:\n",
    "            if chain.id == full_pdb_id[4]:\n",
    "                ground_seq = ''\n",
    "                for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                    ground_seq += pp.get_sequence()\n",
    "                start_pos = ground_seq.find(seq)\n",
    "                if start_pos == -1:\n",
    "                    alignments = pairwise2.align.globalxx(ground_seq, seq)\n",
    "                    al_seq = alignments[0][1]\n",
    "                    bool_seq = [False if a == '-' else True for a in al_seq]\n",
    "                    #start_pos = largest_substring_pos(ground_seq, seq)\n",
    "                    #start_pos = int(alignments[0][2] - 1)\n",
    "                    #end_pos = start_pos + len(al_seq)\n",
    "                    return (-1, -1, bool_seq)\n",
    "                else:\n",
    "                    end_pos = start_pos + len(seq)\n",
    "                    return (start_pos, end_pos, '')\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "# calls dssp api to get dssp file\n",
    "def pdb_id_to_dssp_file(pdb_id, replace=False):\n",
    "    pdb_id = pdb_id.upper()\n",
    "    rest_url = 'http://www.cmbi.umcn.nl/xssp/'\n",
    "    # Read the pdb id data into a variable\n",
    "    data = {'data': pdb_id}\n",
    "\n",
    "    # Send a request to the server to create hssp data from the pdb file data.\n",
    "    # If an error occurs, an exception is raised and the program exits. If the\n",
    "    # request is successful, the id of the job running on the server is\n",
    "    # returned.\n",
    "    url_create = f'{rest_url}api/create/pdb_id/dssp/'\n",
    "    r = requests.post(url_create, data=data)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    job_id = json.loads(r.text)['id']\n",
    "    #print(f'Job submitted successfully. Id is: {job_id}')\n",
    "\n",
    "    # Loop until the job running on the server has finished, either successfully\n",
    "    # or due to an error.\n",
    "    ready = False\n",
    "    while not ready:\n",
    "        # Check the status of the running job. If an error occurs an exception\n",
    "        # is raised and the program exits. If the request is successful, the\n",
    "        # status is returned.\n",
    "        url_status = f'{rest_url}api/status/pdb_id/dssp/{job_id}/'\n",
    "        r = requests.get(url_status)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        status = json.loads(r.text)['status']\n",
    "        #print(f'Job status is: {status}')\n",
    "\n",
    "        # If the status equals SUCCESS, exit out of the loop by changing the\n",
    "        # condition ready. This causes the code to drop into the `else` block\n",
    "        # below.\n",
    "        #\n",
    "        # If the status equals either FAILURE or REVOKED, an exception is raised\n",
    "        # containing the error message. The program exits.\n",
    "        #\n",
    "        # Otherwise, wait for five seconds and start at the beginning of the\n",
    "        # loop again.\n",
    "        if status == 'SUCCESS':\n",
    "            ready = True\n",
    "        elif status in ['FAILURE', 'REVOKED']:\n",
    "            raise Exception(json.loads(r.text)['message'])\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        # Requests the result of the job. If an error occurs an exception is\n",
    "        # raised and the program exits. If the request is successful, the result\n",
    "        # is returned.\n",
    "        url_result = f'{rest_url}api/result/pdb_id/dssp/{job_id}/'\n",
    "        r = requests.get(url_result)\n",
    "        r.raise_for_status()\n",
    "        result = json.loads(r.text)['result']\n",
    "        try:\n",
    "            file_path = os.path.join(dssp_path, f'{pdb_id}.dssp')\n",
    "            if os.path.isfile(file_path) and not replace:\n",
    "                return True\n",
    "            #print(file_path)\n",
    "            file = open(file_path, \"w\")\n",
    "            file.write(result)\n",
    "            file.close()\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            return False\n",
    "        # Return the result to the caller, which prints it to the screen.\n",
    "        return True\n",
    "\n",
    "# uses api call file to generate secondary structure, phi/psi, solvent-accessibility stuff\n",
    "# because of indexing stuff, it crashes if we use partial = True\n",
    "# ask aaron about that\n",
    "def get_ground_truth_api(full_pdb_id, partial=False):\n",
    "    pdb_id = full_pdb_id[0:4].upper()\n",
    "    get_pdb_file(pdb_id)\n",
    "    struct = get_pdb_structure(pdb_id)\n",
    "    ppb = PPBuilder()\n",
    "    struct_info = []\n",
    "    for model in struct:\n",
    "        file = os.path.join(pdb_path, f'{pdb_id}.pdb')\n",
    "        pdb_id_to_dssp_file(pdb_id)\n",
    "        dssp = DSSP(model=model, in_file=os.path.join(dssp_path, f'{pdb_id}.dssp'), file_type='DSSP')\n",
    "        seq_count = 0\n",
    "        #dssp = DSSP(model=model, in_file=file)\n",
    "        for chain in model:\n",
    "            if chain.id == full_pdb_id[4] or not partial:\n",
    "                residues = []\n",
    "                seq = ''\n",
    "                for pp in ppb.build_peptides(chain, aa_only=False):\n",
    "                    seq += pp.get_sequence()\n",
    "                    for residue in pp:\n",
    "                        residues.append(residue)\n",
    "                for i, residue in enumerate(residues):\n",
    "                    try:\n",
    "                        key = list(dssp.keys())[seq_count]   \n",
    "                        dssp_info = dssp[key]\n",
    "                        amino_acid = dssp_info[1]\n",
    "                        sec_struct = dssp_info[2]\n",
    "                        solv_acc = dssp_info[3]\n",
    "                        phi = dssp_info[4]\n",
    "                        psi = dssp_info[5]\n",
    "                    except Exception:\n",
    "                        # DSSP didn't capture this amino acid\n",
    "                        #print(full_pdb_id, seq_count, len(dssp), len(seq), residue)\n",
    "                        amino_acid = seq[i]\n",
    "                        sec_struct = '-'\n",
    "                        solv_acc = 0\n",
    "                        phi = 360\n",
    "                        psi = 360\n",
    "                    seq_count += 1\n",
    "                    # Keys 6 through 13 is bonding energy / relidx (no clue what this is)\n",
    "                    struct_info.append([model.full_id[0], model.full_id[1], chain.id,\n",
    "                        residue.resname, residue.id[1], amino_acid, sec_struct, solv_acc, phi, psi])\n",
    "    info_df = pd.DataFrame(struct_info, \n",
    "        columns=['Model_Name', 'Model_ID', 'Chain', 'Residue_Name',\n",
    "        'Residue_ID', 'Amino_Acid', 'Secondary_Structure', 'Solvent_Accessability', \n",
    "        'Phi', 'Psi'])\n",
    "    if partial:    \n",
    "        start_pos, end_pos, bool_arr = get_seq_pos(full_pdb_id)\n",
    "        if start_pos == -1:\n",
    "            return info_df[bool_arr]\n",
    "        return info_df[start_pos:end_pos]\n",
    "    else:\n",
    "        return info_df\n",
    "\n",
    "\n",
    "    \n",
    "# the following two functions download the files from the api\n",
    "# to create a cache on the disk\n",
    "# speeds things up immensely, only need to run once though\n",
    "def get_ground_truth_files(full_pdb_id, replace=False, partial=False):\n",
    "    bad_list = ['4osnA0']\n",
    "    if full_pdb_id in bad_list:\n",
    "        return 'Bad File'\n",
    "    if partial:\n",
    "        file_path = os.path.join(protein_path, full_pdb_id + '.csv')\n",
    "    else:\n",
    "        file_path = os.path.join(protein_path, full_pdb_id[0:4] + '.csv')\n",
    "        \n",
    "    if os.path.isfile(file_path) and not replace:\n",
    "        return True\n",
    "    \n",
    "    df = get_ground_truth(full_pdb_id, partial)\n",
    "    file_path = ''\n",
    "    try:\n",
    "        df.to_csv(file_path)\n",
    "    except Exception:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def get_cb_distance_files(full_pdb_id, replace=False, partial=False):\n",
    "    bad_list = ['4osnA0']\n",
    "    if full_pdb_id in bad_list:\n",
    "        return 'Bad File'\n",
    "    file_path = ''\n",
    "    if partial:\n",
    "        file_path = os.path.join(distances_path, full_pdb_id + '.csv')\n",
    "        if os.path.isfile(file_path) and not replace:\n",
    "            return True\n",
    "        try:\n",
    "            df = get_cb_distances(full_pdb_id, partial)\n",
    "            df.to_csv(file_path)\n",
    "        except Exception:\n",
    "            return False\n",
    "        return True\n",
    "    else:\n",
    "        df = get_cb_distances(full_pdb_id, partial)\n",
    "        keys = df.keys\n",
    "        for key in keys:\n",
    "            file_path = os.path.join(distances_path, full_pdb_id[0:4] + key + '0.csv')\n",
    "            if os.path.isfile(file_path) and not replace:\n",
    "                return True\n",
    "            try:\n",
    "                df[key].to_csv(file_path)\n",
    "            except Exception:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates the secondary structure ground truth proportions\n",
    "# for a protein in a certain range(start,stop) of amino acids\n",
    "\n",
    "def ss_ground_truth(protein_id, aa_range,secs):\n",
    "    sstructs=\"HBEGITS\"\n",
    "\n",
    "#     print(aa_range)\n",
    "#     k=secs[secs['Chain']==protein_id[4]]\n",
    "    k=secs.iloc[aa_range,:]\n",
    "\n",
    "    ss_count=[]\n",
    "\n",
    "    for ss in sstructs:\n",
    "        ss_count.append(len(k[k['Secondary_Structure']==ss])/len(k))\n",
    "\n",
    "    return ss_count\n",
    "\n",
    "# H = alpha helix\n",
    "# B = residue in isolated beta-bridge\n",
    "# E = extended strand, participates in beta ladder\n",
    "# G = 3-helix (3/10 helix)\n",
    "# I = 5 helix (pi helix)\n",
    "# T = hydrogen bonded turn\n",
    "# S = bend\n",
    "\n",
    "\n",
    "# DON'T USE THIS\n",
    "# its too intensive to call it over and over again\n",
    "def format_torsion_angles_to_dataframe(pdb_id, start, chip_size):\n",
    "    \n",
    "    get_pdb_file(pdb_id)\n",
    "    \n",
    "    angles=[]\n",
    "    ta=get_torsion_angles(pdb_id)\n",
    "\n",
    "    angles+=list(ta.iloc[start:start+chip_size,:][\"Phi\"])\n",
    "    angles+=list(ta.iloc[start:start+chip_size,:][\"Psi\"])\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def get_torsion_for_df(pdb_id):\n",
    "    get_pdb_file(pdb_id)\n",
    "    return get_torsion_angles(pdb_id)\n",
    "\n",
    "def distance_map_from_file(pdb_id):\n",
    "    k= np.genfromtxt(os.path.join(\"computed_distance_cache\",pdb_id+\".csv\"), delimiter=',',skip_header =1)\n",
    "    return np.delete(k,0,1)\n",
    "\n",
    "def get_ground_truth_from_file(pdb_id):\n",
    "    return pandas.read_csv(os.path.join(\"computed_ground_truth_cache\",pdb_id.upper()+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "\n",
    "# mean function\n",
    "# just for utility purposes\n",
    "def mean(numlist):\n",
    "    return sum(numlist)/len(numlist)\n",
    "\n",
    "# this creates triangular chips along (but not including)\n",
    "# the diagonal within the comparison matrix\n",
    "def chip_diagonal(chip_size, step_size, aa_length):\n",
    "    tri=[]\n",
    "    for diag in range(0,aa_length-chip_size,step_size):\n",
    "        tri.append(\n",
    "            [(y,x) for y in range(diag,diag+chip_size) for x in range(y+1,chip_size+diag+1)]\n",
    "        )\n",
    "        # NB: y already has diag added to it\n",
    "    return tri\n",
    "\n",
    "def chip_diag_fast(chip_size):\n",
    "    return [(y,x) for y in range(0,chip_size) for x in range(y+1,chip_size+1)]\n",
    "\n",
    "# create a gif showing where the triangular chipping window is located\n",
    "def gif_from_tri(protein_id,tri,filename):\n",
    "    \n",
    "    protein = np.array(distance_maps_cb[protein_id])\n",
    "    l=len(protein)\n",
    "\n",
    "    gif=[]\n",
    "\n",
    "    for t in tri:\n",
    "        new_test=np.ones((l,l))*0\n",
    "        for (y,x) in t:\n",
    "            new_test[y,x]=protein[y,x]\n",
    "\n",
    "        im=plt.imshow(new_test)\n",
    "\n",
    "        x=im.make_image(\"AGG\")[0]\n",
    "        x=np.flipud(x)\n",
    "\n",
    "        gif.append(np.array(x))\n",
    "\n",
    "    imageio.mimsave(filename+'.gif', gif, fps=5)\n",
    "\n",
    "\n",
    "# create a dataframe from a given protein id, chip size, and step size\n",
    "def diag_chips_to_df(protein_id, chip_size, step_size):\n",
    "    \n",
    "    # arrange all the feature matrices into proper form so we can \n",
    "    # reference them properly later\n",
    "        \n",
    "#         cb_dist_cache\n",
    "    test_distmap=distance_map_from_file(protein_id)\n",
    "    if test_distmap is not None:\n",
    "        protein_dist=test_distmap\n",
    "    elif (protein_id + \".csv\" in os.listdir(\"./cb_dist_cache\")):\n",
    "        protein_dist=pandas.read_csv(os.path.join(\"cb_dist_cache\",(protein_id + \".csv\")))\n",
    "    else:\n",
    "        protein_dist = np.array(get_cb_distances(protein_id,partial=True))\n",
    "    \n",
    "    aa_length=protein_dist.shape[0]\n",
    "#     print(aa_length)\n",
    "    \n",
    "    protein_feat = np.array(input_features[protein_id])\n",
    "\n",
    "    feat_len=protein_feat[0].shape[0]\n",
    "    pad_len=aa_length-feat_len\n",
    "    \n",
    "    if pad_len<0:\n",
    "        print(\"ERROR: NEGATIVE PAD LENGTH FOR \"+ protein_id)\n",
    "        print(\"AA_LEN: \"+str(aa_length))\n",
    "        print(\"FEAT_LEN: \"+str(feat_len))\n",
    "    \n",
    "    ccmpred=protein_feat[5].astype(np.float)\n",
    "    ccmpred.shape=(feat_len,feat_len)\n",
    "    ccmpred=np.pad(ccmpred,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    freecontact=protein_feat[6].astype(np.float)\n",
    "    freecontact.shape=(feat_len,feat_len)\n",
    "    freecontact=np.pad(freecontact,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    pstat_pots=protein_feat[7].astype(np.float)\n",
    "    pstat_pots.shape=(feat_len,feat_len)\n",
    "    pstat_pots=np.pad(pstat_pots,pad_len,'constant', constant_values=(0))\n",
    "    \n",
    "    chip=chip_diag_fast(chip_size)\n",
    "    chip_offsets=[(d,d) for d in range(0,aa_length-chip_size,step_size)]\n",
    "      \n",
    "    chips=[[tuple(sum(t) for t in zip(a,(d,d))) for a in chip] for d in range(0,aa_length-chip_size,step_size)]\n",
    "    \n",
    "    print(protein_id)\n",
    "    \n",
    "# check ground_truth_cache\n",
    "    test_gt=get_ground_truth_from_file(protein_id)\n",
    "    if(test_gt is not None):\n",
    "        gt=test_gt\n",
    "    elif (protein_id.upper() + \".csv\" in os.listdir(\"./ground_truth_cache\")):\n",
    "        gt=pandas.read_csv(os.path.join(\"ground_truth_cache\",(protein_id.upper() + \".csv\")))\n",
    "    else:\n",
    "        gt=get_ground_truth_api(protein_id,partial=True) # set to inverse\n",
    "    \n",
    "    # create column labels\n",
    "    cols=[\"protein_id\",\"chip_id\"]\n",
    "    cols+=[\"start\",\"stop\"]\n",
    "    cols+=[\"dist_\"+str(n) for n in range(0,len(chips[0]))]\n",
    "    cols+=[\"psipred_helix\",\"psipred_sheet\",\"psipred_coil\"]\n",
    "    cols+=[\"psisolv\",\"shannon_entropy\"]\n",
    "    cols+=[\"ccmpred\",\"freecontact\",\"pstat_pots\"]\n",
    "    cols+=[\"ground_truth_\"+x for x in \"HBEGITS\"]\n",
    "    cols+=[\"phi_\"+str(x) for x in range(0,chip_size)]\n",
    "    cols+=[\"psi_\"+str(x) for x in range(0,chip_size)]\n",
    "    cols+=[\"solv_access_\"+str(x) for x in range(0,chip_size)]\n",
    "\n",
    "    \n",
    "    chiplist=[]\n",
    "    \n",
    "    t_phi=list(gt['Phi'])\n",
    "    t_psi=list(gt['Psi'])\n",
    "    t_solv=list(gt['Solvent_Accessability'])\n",
    "    \n",
    "    # loop through all the chips\n",
    "    for i in range(0,len(chips)):\n",
    "        \n",
    "        # row identifiers\n",
    "        row=[protein_id,\"chip_\"+str(i)]\n",
    "        row+=[i,i+chip_size]\n",
    "        \n",
    "        # inclusion range\n",
    "        # between the first amino acid being compared \n",
    "        # and the last amino acid being compared\n",
    "        # NB this assumes that \n",
    "        incl_range=range(min(min(chips[i])),max(max(chips[i])))\n",
    "        \n",
    "        # 1d features\n",
    "        base_helix=protein_feat[0].astype(np.float)\n",
    "        base_sheet=protein_feat[1].astype(np.float)\n",
    "        base_coil=protein_feat[2].astype(np.float)\n",
    "        base_solv=protein_feat[3].astype(np.float)\n",
    "        base_shan=protein_feat[4].astype(np.float)\n",
    "        \n",
    "        base_helix=np.pad(base_helix,pad_len,'constant', constant_values=(0))\n",
    "        base_sheet=np.pad(base_sheet,pad_len,'constant', constant_values=(0))\n",
    "        base_coil=np.pad(base_coil,pad_len,'constant', constant_values=(0))\n",
    "        base_solv=np.pad(base_solv,pad_len,'constant', constant_values=(0))\n",
    "        base_shan=np.pad(base_shan,pad_len,'constant', constant_values=(0))\n",
    "        \n",
    "        psipred_helix=mean(base_helix[incl_range])\n",
    "        psipred_sheet=mean(base_sheet[incl_range])\n",
    "        psipred_coil=mean(base_coil[incl_range])\n",
    "        psisolv=mean(base_solv[incl_range])\n",
    "        shannon_entropy=mean(base_shan[incl_range])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 2d features\n",
    "        ccmpred_pool=[]\n",
    "        freecontact_pool=[]\n",
    "        pstat_pool=[]\n",
    "        \n",
    "        # ss ground truth\n",
    "        ssgt=ss_ground_truth(protein_id,incl_range,gt)\n",
    "        \n",
    "        # loop through each pixel in the chip\n",
    "        for n in range(0,len(chips[i])):\n",
    "            \n",
    "#             make sure we're not on the diagonal\n",
    "#             print([chips[i][n][0],chips[i][n][1]])\n",
    "            \n",
    "            row.append(\n",
    "                protein_dist[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            ccmpred_pool.append(\n",
    "                ccmpred[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            freecontact_pool.append(\n",
    "                freecontact[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            pstat_pool.append(\n",
    "                pstat_pots[chips[i][n][0],chips[i][n][1]]\n",
    "            )\n",
    "            \n",
    "        # 1d features\n",
    "        row.append(psipred_helix)\n",
    "        row.append(psipred_sheet)\n",
    "        row.append(psipred_coil)\n",
    "        row.append(psisolv)\n",
    "        row.append(shannon_entropy)\n",
    "   \n",
    "        # 2d features\n",
    "        row.append(max(ccmpred_pool))\n",
    "        row.append(max(freecontact_pool))\n",
    "        row.append(max(pstat_pool))\n",
    "        \n",
    "        # ground truth\n",
    "        [row.append(x) for x in ssgt]\n",
    "        \n",
    "        # torsional angles\n",
    "        row+=t_phi[i:i+chip_size]\n",
    "        row+=t_psi[i:i+chip_size]\n",
    "        row+=t_solv[i:i+chip_size]\n",
    "#         print(row)\n",
    "        \n",
    "        # add to df\n",
    "        chiplist.append(row)\n",
    "\n",
    "#     AssertionError: 94 columns passed, passed data had 75 columns\n",
    "# almost correct number of columns, but torsion angles not being passed correctly?\n",
    "    chip_df=pandas.DataFrame(chiplist,columns=cols)\n",
    "\n",
    "    return chip_df\n",
    "\n",
    "\n",
    "# compute the ground truth secondary structure\n",
    "# of which the majority of amino acids in a window\n",
    "# are a part of\n",
    "# i.e. that whose percentage within the window is above 50%\n",
    "def compute_majority_ss(df):\n",
    "    for ss in \"HBEGITS\":\n",
    "        df[\"maj_\"+ss]=df['ground_truth_'+ss]>.5\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12asA0\n",
      "16pkA0\n",
      "16vpA0\n",
      "1a0tP0\n",
      "1a2zA0\n",
      "1a8rA0\n",
      "1ahsA0\n",
      "1aihA0\n",
      "1aisB0\n",
      "1am9A0\n"
     ]
    }
   ],
   "source": [
    "# this is the thing\n",
    "# this makes the whole dataset\n",
    "# these three lines below\n",
    "# just run these and it'll make the dataset\n",
    "\n",
    "dataset=pandas.concat([(diag_chips_to_df(pid,25,1)) for pid in [x for x in pdb_list_y if x not in ignore_list]])\n",
    "compute_majority_ss(dataset)\n",
    "dataset.to_csv(\"datasets/protein_all_25.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate the gif function\n",
    "\n",
    "# gif_from_tri(\"1hzfA0\",chip_diagonal(50,1,256),\"chiptri_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demonstrate how to create a dataset from it\n",
    "\n",
    "# parallel processing screws things up in a weird way\n",
    "# which isn't reproducible using single-threading\n",
    "# we'll single-thread it to avoid this\n",
    "\n",
    "if False:\n",
    "\n",
    "    def chip_parallel(x):\n",
    "        return diag_chips_to_df(x,25,1)\n",
    "\n",
    "    start_time=time.clock()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=available_cpu) as executor:\n",
    "        dataset=pandas.concat(executor.map(chip_parallel, [x for x in pdb_list_y if x not in ignore_list]))\n",
    "    print(\"parallel completed in \"+ str(time.clock()-start_time))\n",
    "    compute_majority_ss(dataset)\n",
    "\n",
    "    dataset\n",
    "    dataset.to_csv(\"datasets/protein_all_25.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12asA0\n",
      "16pkA0\n",
      "16vpA0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n",
      "D:\\Programs\\lib\\site-packages\\Bio\\PDB\\Polypeptide.py:328: UserWarning: Assuming residue  CA is an unknown modified amino acid\n",
      "  \"amino acid\" % residue.get_resname())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a0tP0\n",
      "1a2zA0\n",
      "1a8rA0\n",
      "1ahsA0\n",
      "1aihA0\n",
      "1aisB0\n",
      "1am9A0\n"
     ]
    }
   ],
   "source": [
    "dataset=pandas.concat([(diag_chips_to_df(pid,10,1)) for pid in [x for x in pdb_list_y[0:10] if x not in ignore_list]])\n",
    "\n",
    "# get_pdb_file(\"12AS\")\n",
    "\n",
    "# pdb_list_y[0:10]\n",
    "\n",
    "# df=diag_chips_to_df(pdb_list_y[77],10,1)\n",
    "\n",
    "# gt=get_ground_truth_api(\"1eerA0\",partial=True)\n",
    "\n",
    "# get_cb_distances(\"1dzfA0\",partial=True)\n",
    "\n",
    "# pdb_list_y.index(\"1ek9A0\")\n",
    "\n",
    "# pdb_list_y[77]\n",
    "\n",
    "# [x for x in pdb_list_y if x not in ignore_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protein_id',\n",
       " 'chip_id',\n",
       " 'start',\n",
       " 'stop',\n",
       " 'dist_0',\n",
       " 'dist_1',\n",
       " 'dist_2',\n",
       " 'dist_3',\n",
       " 'dist_4',\n",
       " 'dist_5',\n",
       " 'dist_6',\n",
       " 'dist_7',\n",
       " 'dist_8',\n",
       " 'dist_9',\n",
       " 'dist_10',\n",
       " 'dist_11',\n",
       " 'dist_12',\n",
       " 'dist_13',\n",
       " 'dist_14',\n",
       " 'dist_15',\n",
       " 'dist_16',\n",
       " 'dist_17',\n",
       " 'dist_18',\n",
       " 'dist_19',\n",
       " 'dist_20',\n",
       " 'dist_21',\n",
       " 'dist_22',\n",
       " 'dist_23',\n",
       " 'dist_24',\n",
       " 'dist_25',\n",
       " 'dist_26',\n",
       " 'dist_27',\n",
       " 'dist_28',\n",
       " 'dist_29',\n",
       " 'dist_30',\n",
       " 'dist_31',\n",
       " 'dist_32',\n",
       " 'dist_33',\n",
       " 'dist_34',\n",
       " 'dist_35',\n",
       " 'dist_36',\n",
       " 'dist_37',\n",
       " 'dist_38',\n",
       " 'dist_39',\n",
       " 'dist_40',\n",
       " 'dist_41',\n",
       " 'dist_42',\n",
       " 'dist_43',\n",
       " 'dist_44',\n",
       " 'dist_45',\n",
       " 'dist_46',\n",
       " 'dist_47',\n",
       " 'dist_48',\n",
       " 'dist_49',\n",
       " 'dist_50',\n",
       " 'dist_51',\n",
       " 'dist_52',\n",
       " 'dist_53',\n",
       " 'dist_54',\n",
       " 'psipred_helix',\n",
       " 'psipred_sheet',\n",
       " 'psipred_coil',\n",
       " 'psisolv',\n",
       " 'shannon_entropy',\n",
       " 'ccmpred',\n",
       " 'freecontact',\n",
       " 'pstat_pots',\n",
       " 'ground_truth_H',\n",
       " 'ground_truth_B',\n",
       " 'ground_truth_E',\n",
       " 'ground_truth_G',\n",
       " 'ground_truth_I',\n",
       " 'ground_truth_T',\n",
       " 'ground_truth_S',\n",
       " 'phi_0',\n",
       " 'phi_1',\n",
       " 'phi_2',\n",
       " 'phi_3',\n",
       " 'phi_4',\n",
       " 'phi_5',\n",
       " 'phi_6',\n",
       " 'phi_7',\n",
       " 'phi_8',\n",
       " 'phi_9',\n",
       " 'psi_0',\n",
       " 'psi_1',\n",
       " 'psi_2',\n",
       " 'psi_3',\n",
       " 'psi_4',\n",
       " 'psi_5',\n",
       " 'psi_6',\n",
       " 'psi_7',\n",
       " 'psi_8',\n",
       " 'psi_9',\n",
       " 'solv_access_0',\n",
       " 'solv_access_1',\n",
       " 'solv_access_2',\n",
       " 'solv_access_3',\n",
       " 'solv_access_4',\n",
       " 'solv_access_5',\n",
       " 'solv_access_6',\n",
       " 'solv_access_7',\n",
       " 'solv_access_8',\n",
       " 'solv_access_9']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get_ground_truth_api(pdb_list_y[0][0:4])\n",
    "# gt\n",
    "\n",
    "# pdb_list_y[76]\n",
    "# get_ground_truth_api(pdb_list_y[77],partial=True)\n",
    "\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will add majority secondary structure to the dataframe\n",
    "# through loading it from file\n",
    "# i've dummied it out through the if statement but its still usefull\n",
    "if False:\n",
    "    dataset=pandas.read_csv(\"datasets/protein_full_gt.csv\")\n",
    "\n",
    "    compute_majority_ss(dataset)\n",
    "    dataset.to_csv(\"datasets/protein_full_gt_classed.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these generate triangular numbers from a row number\n",
    "# and row numbers from a triangular number\n",
    "# not sure if I use them anymore but here they are\n",
    "def tri_num(x):\n",
    "    return x*(x+1)/2\n",
    "    \n",
    "def inv_tri_num(x):\n",
    "    for i in range(0,x):\n",
    "        if tri_num(i)>x:\n",
    "            return None\n",
    "        if tri_num(i)==x:\n",
    "            return i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this draws a gif from a number of chips l\n",
    "# which will iterate through the rows of a datafile\n",
    "# and make each row (and the chip represented by that row)\n",
    "# into a frame of the gif\n",
    "def gif_from_chips(dataset,l,filename):    \n",
    "\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "    \n",
    "    gif=[]\n",
    "\n",
    "    for n in range(0,l):\n",
    "        \n",
    "        chpx=list(df.iloc[n,:])\n",
    "\n",
    "        chip_l=inv_tri_num(ncol)+1\n",
    "        chp_im=np.zeros((chip_l,chip_l))\n",
    "        triu=np.triu_indices(chip_l,1)\n",
    "        tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "\n",
    "        for i in range(0,len(tri_ind)):\n",
    "             chp_im[tri_ind[i][0],tri_ind[i][1]]=chpx[i]\n",
    "\n",
    "        im=plt.imshow(chp_im)    \n",
    "\n",
    "        \n",
    "        x=im.make_image(\"AGG\")[0]\n",
    "        x=np.flipud(x)\n",
    "\n",
    "        gif.append(np.array(x))\n",
    "\n",
    "    imageio.mimsave(filename+'.gif', gif, fps=60)\n",
    "\n",
    "    \n",
    "    \n",
    "# this is a function which will draw the average chip\n",
    "# of a dataset\n",
    "# i.e. draw a chip whose pixels are each an average of the\n",
    "# pixels in that position on each chip\n",
    "def draw_avg_chip(dataset, name, max_dist):\n",
    "    \n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "#     print(ncol)\n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.zeros((chip_l,chip_l))\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    for i in range(0,len(tri_ind)):\n",
    "         chp_im[tri_ind[i][0],tri_ind[i][1]]=chpx[i]\n",
    "\n",
    "    im=plt.imshow(chp_im,vmax=max_dist)\n",
    "    \n",
    "    x=im.make_image(\"AGG\")[0]\n",
    "    x=np.flipud(x)\n",
    "    \n",
    "    imageio.imsave(\"plots/\"+name+\".png\", x)\n",
    "    \n",
    "# as above, but draws a lineplot instead of a chip\n",
    "def draw_avg_dist_lineplot(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(tri_ind)):\n",
    "         chp_im[tri_ind[i][0],tri_ind[i][1]-tri_ind[i][0]]=chpx[i]\n",
    "\n",
    "    plt.ylim((0, max_dist))\n",
    "    plt.plot(np.nanmean(chp_im,0))\n",
    "    \n",
    "    plt.savefig(\"plots/lineg/\"+name+\".png\")\n",
    "    plt.cla()\n",
    "\n",
    "# as above, but draws a densityplot instead of a lineplot\n",
    "def draw_avg_dist_densityplot(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "    \n",
    "    chpx=list(df.mean(0))\n",
    "    \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "    seq_dist=[triu[1][i]-triu[0][i] for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    cx=[]\n",
    "    cy=[]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(0,len(seq_dist)):\n",
    "            cx.append(seq_dist[i])\n",
    "            cy.append(row[i])\n",
    "\n",
    "    plt.ylim((0, max_dist))\n",
    "\n",
    "    plt.hist2d(cx,cy)\n",
    " \n",
    "    plt.savefig(\"plots/2dhist/\"+name+\".png\")\n",
    "    plt.cla()\n",
    "    \n",
    "    \n",
    "    # as above, but draws a densityplot which does not have an\n",
    "    # artificially brightened area for lower amino acid sequence distances\n",
    "    # because we average across sequence distance per chip\n",
    "    # before averaging across chips\n",
    "def draw_avg_dist_densityplot2(dataset, name,max_dist):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "        \n",
    "    chip_l=inv_tri_num(ncol)+1\n",
    "    chp_im=np.empty((chip_l,chip_l))\n",
    "    chp_im[:]=np.nan\n",
    "    chp_im[:,0]=0\n",
    "    triu=np.triu_indices(chip_l,1)\n",
    "\n",
    "    tri_ind=[(triu[0][i],triu[1][i]) for i in range(0,len(triu[0]))]\n",
    "    \n",
    "    cx=[]\n",
    "    cy=[]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for i in range(0,chip_l):\n",
    "            chp_im[tri_ind[i][0],tri_ind[i][1]-tri_ind[i][0]]=row[i]\n",
    "        \n",
    "        cx+=(list(range(1,chip_l)))\n",
    "        cy+=list(np.nanmean(chp_im,0))[1:]\n",
    "\n",
    "    xbins=np.linspace(1,chip_l,chip_l)\n",
    "    ybins=np.linspace(1,max_dist,chip_l*2)\n",
    "    \n",
    "\n",
    "    plt.hist2d(cx,cy,bins = (xbins,ybins))\n",
    " \n",
    "    plt.savefig(\"plots/2dhist/\"+name+\".png\")\n",
    "    \n",
    "def get_avg_distances(dataset):\n",
    "    ncol=len([c for c in dataset.columns if c[0:5]==\"dist_\"])\n",
    "    \n",
    "    df=dataset[[\"dist_\"+str(x) for x in range(0,ncol)]]\n",
    "\n",
    "    return(list(df.mean(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset=pandas.read_csv(\"datasets/protein_test_gt.csv\")\n",
    "\n",
    "\n",
    "draw_avg_dist_densityplot2(dataset.iloc[0:100,:],\"test\",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate the gif_from_chips function\n",
    "# which draws an animated gif of a number of chips from a saved dataset\n",
    "\n",
    "# gif_from_chips(dataset,500,\"chip_draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this draws the avg distance for each pixel in all chips\n",
    "# within each point in a thd dendrogram\n",
    "\n",
    "def draw_thd_segmentations(folder,prefix,dataset):\n",
    "    tda_dir=\"datasets/\"+folder\n",
    "\n",
    "    thds=[n for n in os.listdir(tda_dir) if n[0:len(prefix)]==prefix]\n",
    "        \n",
    "    df_list=[]\n",
    "    names=[]\n",
    "    maxes=[]\n",
    "    \n",
    "    for model in thds:\n",
    "        \n",
    "        with open(tda_dir+model) as jsonf:\n",
    "            a=json.load(jsonf)\n",
    "            \n",
    "            df=dataset.iloc[[int(m) for m in a['rowList']],:]\n",
    "            \n",
    "#             print(model)\n",
    "#             print([int(m) for m in a['rowList']])\n",
    "            \n",
    "            maxes.append(max(get_avg_distances(df)))\n",
    "            df_list.append(df)\n",
    "            names.append(model[len(prefix):len(model)-5])\n",
    "            \n",
    "    max_dist=max(maxes)\n",
    "    for i in range(0,len(df_list)):\n",
    "#         draw_avg_chip(df_list[i],names[i],max_dist)\n",
    "#         draw_avg_dist_lineplot(df_list[i],names[i],max_dist)\n",
    "#         draw_avg_dist_densityplot(df_list[i],names[i],max_dist)\n",
    "        draw_avg_dist_densityplot2(df_list[i],names[i],max_dist)\n",
    "\n",
    "def thd_row_lengths(folder,prefix):\n",
    "    tda_dir=\"datasets/\"+folder\n",
    "\n",
    "    thds=[n for n in os.listdir(tda_dir) if n[0:len(prefix)]==prefix]\n",
    "    \n",
    "    d={}\n",
    "    \n",
    "    for model in thds:\n",
    "        \n",
    "        with open(tda_dir+model) as jsonf:\n",
    "            a=json.load(jsonf)\n",
    "\n",
    "            d[model]=a['meta']['row_count']\n",
    "    \n",
    "    for i in d:\n",
    "        print(i +\" \"+ str(round(d[i]/max(d.values()),2)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demonstrate draw_thd_segmentations\n",
    "\n",
    "# read in the dataset to use below\n",
    "# dataset=pandas.read_csv(\"datasets/protein_test_gt.csv\")\n",
    "\n",
    "\n",
    "#     draw_thd_segmentations(\"thd_test__Absolute Correlation_protein_test_gt_majority.csv_2019.06.18 15.51.08/\",\"thd_test_ \",dataset)\n",
    "# thd_row_lengths(\"thd_test__Absolute Correlation_protein_test_gt_majority.csv_2019.06.18 15.51.08/\",\"thd_test_ \")\n",
    "\n",
    "#     draw_thd_segmentations(\"THD_test_Absolute Correlation_protein_test_fifteen_gt.csv_2019.06.19 14.20.55/\",\"THD_test \",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screwing around with showing secondary structures in chart\n",
    "def twod_secondary_struct(pdb_id):\n",
    "    dim=length_dict[pdb_id]\n",
    "    k=distance_maps_cb[pdb_id].astype(float).reshape(dim,dim)\n",
    "\n",
    "    plt.imshow(np.triu(k))\n",
    "    plt.show()\n",
    "\n",
    "    helix=np.matrix(input_features[pdb_id][0].astype(float))\n",
    "    k=np.repeat(helix,dim,0)\n",
    "\n",
    "    plt.imshow(np.triu(np.transpose(k)*k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model_ID</th>\n",
       "      <th>Chain</th>\n",
       "      <th>Residue_Name</th>\n",
       "      <th>Residue_ID</th>\n",
       "      <th>Amino_Acid</th>\n",
       "      <th>Secondary_Structure</th>\n",
       "      <th>Solvent_Accessability</th>\n",
       "      <th>Phi</th>\n",
       "      <th>Psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ALA</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>-</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>360.0</td>\n",
       "      <td>157.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TYR</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>H</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>-41.6</td>\n",
       "      <td>-56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ILE</td>\n",
       "      <td>6</td>\n",
       "      <td>I</td>\n",
       "      <td>H</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>-55.5</td>\n",
       "      <td>-51.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ALA</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>0.462264</td>\n",
       "      <td>-54.4</td>\n",
       "      <td>-58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LYS</td>\n",
       "      <td>8</td>\n",
       "      <td>K</td>\n",
       "      <td>H</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>-54.3</td>\n",
       "      <td>-39.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLN</td>\n",
       "      <td>9</td>\n",
       "      <td>Q</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61.4</td>\n",
       "      <td>-33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ARG</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>-86.1</td>\n",
       "      <td>-32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLN</td>\n",
       "      <td>11</td>\n",
       "      <td>Q</td>\n",
       "      <td>H</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-52.9</td>\n",
       "      <td>-57.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ILE</td>\n",
       "      <td>12</td>\n",
       "      <td>I</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-53.8</td>\n",
       "      <td>-50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>SER</td>\n",
       "      <td>13</td>\n",
       "      <td>S</td>\n",
       "      <td>H</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-55.7</td>\n",
       "      <td>-41.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>PHE</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.279188</td>\n",
       "      <td>-64.6</td>\n",
       "      <td>-44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>VAL</td>\n",
       "      <td>15</td>\n",
       "      <td>V</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61.1</td>\n",
       "      <td>-54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LYS</td>\n",
       "      <td>16</td>\n",
       "      <td>K</td>\n",
       "      <td>H</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>-62.5</td>\n",
       "      <td>-29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>SER</td>\n",
       "      <td>17</td>\n",
       "      <td>S</td>\n",
       "      <td>H</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>-80.5</td>\n",
       "      <td>-53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>HIS</td>\n",
       "      <td>18</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>-53.4</td>\n",
       "      <td>-50.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>PHE</td>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-67.3</td>\n",
       "      <td>-28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>SER</td>\n",
       "      <td>20</td>\n",
       "      <td>S</td>\n",
       "      <td>H</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>-57.8</td>\n",
       "      <td>-42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ARG</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>0.524194</td>\n",
       "      <td>-70.4</td>\n",
       "      <td>-32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLN</td>\n",
       "      <td>22</td>\n",
       "      <td>Q</td>\n",
       "      <td>H</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>-59.1</td>\n",
       "      <td>-34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>23</td>\n",
       "      <td>L</td>\n",
       "      <td>H</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>-75.1</td>\n",
       "      <td>-35.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLU</td>\n",
       "      <td>24</td>\n",
       "      <td>E</td>\n",
       "      <td>H</td>\n",
       "      <td>0.396907</td>\n",
       "      <td>-74.7</td>\n",
       "      <td>-37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLU</td>\n",
       "      <td>25</td>\n",
       "      <td>E</td>\n",
       "      <td>H</td>\n",
       "      <td>0.644330</td>\n",
       "      <td>-87.6</td>\n",
       "      <td>-40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ARG</td>\n",
       "      <td>26</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>-75.4</td>\n",
       "      <td>-28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>27</td>\n",
       "      <td>L</td>\n",
       "      <td>H</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>-123.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLY</td>\n",
       "      <td>28</td>\n",
       "      <td>G</td>\n",
       "      <td>-</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>61.8</td>\n",
       "      <td>44.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>29</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>-104.2</td>\n",
       "      <td>137.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ILE</td>\n",
       "      <td>30</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0.201183</td>\n",
       "      <td>-102.2</td>\n",
       "      <td>152.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLU</td>\n",
       "      <td>31</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>0.262887</td>\n",
       "      <td>-76.6</td>\n",
       "      <td>134.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>VAL</td>\n",
       "      <td>32</td>\n",
       "      <td>V</td>\n",
       "      <td>-</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>-124.3</td>\n",
       "      <td>155.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLN</td>\n",
       "      <td>33</td>\n",
       "      <td>Q</td>\n",
       "      <td>-</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-73.8</td>\n",
       "      <td>129.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ALA</td>\n",
       "      <td>230</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>-80.2</td>\n",
       "      <td>136.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLY</td>\n",
       "      <td>231</td>\n",
       "      <td>G</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.6</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>232</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>-112.1</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASN</td>\n",
       "      <td>233</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-136.8</td>\n",
       "      <td>174.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>230</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLY</td>\n",
       "      <td>234</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.6</td>\n",
       "      <td>-172.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASP</td>\n",
       "      <td>235</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>-117.3</td>\n",
       "      <td>152.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>232</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ILE</td>\n",
       "      <td>236</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>-91.1</td>\n",
       "      <td>128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>233</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>237</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>-134.5</td>\n",
       "      <td>135.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>VAL</td>\n",
       "      <td>238</td>\n",
       "      <td>V</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-129.0</td>\n",
       "      <td>165.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>TRP</td>\n",
       "      <td>239</td>\n",
       "      <td>W</td>\n",
       "      <td>E</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>-79.9</td>\n",
       "      <td>116.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASN</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>-90.4</td>\n",
       "      <td>111.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>PRO</td>\n",
       "      <td>241</td>\n",
       "      <td>P</td>\n",
       "      <td>T</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>-17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>VAL</td>\n",
       "      <td>242</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>243</td>\n",
       "      <td>L</td>\n",
       "      <td>T</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>-83.1</td>\n",
       "      <td>-8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLU</td>\n",
       "      <td>244</td>\n",
       "      <td>E</td>\n",
       "      <td>T</td>\n",
       "      <td>0.711340</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASP</td>\n",
       "      <td>245</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>-150.5</td>\n",
       "      <td>172.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ALA</td>\n",
       "      <td>246</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>-73.9</td>\n",
       "      <td>145.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>PHE</td>\n",
       "      <td>247</td>\n",
       "      <td>F</td>\n",
       "      <td>E</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>-130.7</td>\n",
       "      <td>109.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLU</td>\n",
       "      <td>248</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>-79.1</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>LEU</td>\n",
       "      <td>249</td>\n",
       "      <td>L</td>\n",
       "      <td>E</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>SER</td>\n",
       "      <td>250</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>-168.1</td>\n",
       "      <td>154.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>SER</td>\n",
       "      <td>251</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>-131.6</td>\n",
       "      <td>126.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>MET</td>\n",
       "      <td>252</td>\n",
       "      <td>M</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-140.1</td>\n",
       "      <td>179.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>GLY</td>\n",
       "      <td>253</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.8</td>\n",
       "      <td>152.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ILE</td>\n",
       "      <td>254</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-64.1</td>\n",
       "      <td>139.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ARG</td>\n",
       "      <td>255</td>\n",
       "      <td>R</td>\n",
       "      <td>B</td>\n",
       "      <td>0.028226</td>\n",
       "      <td>-87.3</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>252</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>VAL</td>\n",
       "      <td>256</td>\n",
       "      <td>V</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.1</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASP</td>\n",
       "      <td>257</td>\n",
       "      <td>D</td>\n",
       "      <td>-</td>\n",
       "      <td>0.343558</td>\n",
       "      <td>-109.2</td>\n",
       "      <td>-171.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ALA</td>\n",
       "      <td>258</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>0.254717</td>\n",
       "      <td>-63.7</td>\n",
       "      <td>-36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>12AS</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>ASP</td>\n",
       "      <td>259</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>0.730061</td>\n",
       "      <td>-80.8</td>\n",
       "      <td>-35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 Model_Name  Model_ID Chain Residue_Name  Residue_ID  \\\n",
       "0             0       12AS         0     A          ALA           4   \n",
       "1             1       12AS         0     A          TYR           5   \n",
       "2             2       12AS         0     A          ILE           6   \n",
       "3             3       12AS         0     A          ALA           7   \n",
       "4             4       12AS         0     A          LYS           8   \n",
       "5             5       12AS         0     A          GLN           9   \n",
       "6             6       12AS         0     A          ARG          10   \n",
       "7             7       12AS         0     A          GLN          11   \n",
       "8             8       12AS         0     A          ILE          12   \n",
       "9             9       12AS         0     A          SER          13   \n",
       "10           10       12AS         0     A          PHE          14   \n",
       "11           11       12AS         0     A          VAL          15   \n",
       "12           12       12AS         0     A          LYS          16   \n",
       "13           13       12AS         0     A          SER          17   \n",
       "14           14       12AS         0     A          HIS          18   \n",
       "15           15       12AS         0     A          PHE          19   \n",
       "16           16       12AS         0     A          SER          20   \n",
       "17           17       12AS         0     A          ARG          21   \n",
       "18           18       12AS         0     A          GLN          22   \n",
       "19           19       12AS         0     A          LEU          23   \n",
       "20           20       12AS         0     A          GLU          24   \n",
       "21           21       12AS         0     A          GLU          25   \n",
       "22           22       12AS         0     A          ARG          26   \n",
       "23           23       12AS         0     A          LEU          27   \n",
       "24           24       12AS         0     A          GLY          28   \n",
       "25           25       12AS         0     A          LEU          29   \n",
       "26           26       12AS         0     A          ILE          30   \n",
       "27           27       12AS         0     A          GLU          31   \n",
       "28           28       12AS         0     A          VAL          32   \n",
       "29           29       12AS         0     A          GLN          33   \n",
       "..          ...        ...       ...   ...          ...         ...   \n",
       "226         226       12AS         0     A          ALA         230   \n",
       "227         227       12AS         0     A          GLY         231   \n",
       "228         228       12AS         0     A          LEU         232   \n",
       "229         229       12AS         0     A          ASN         233   \n",
       "230         230       12AS         0     A          GLY         234   \n",
       "231         231       12AS         0     A          ASP         235   \n",
       "232         232       12AS         0     A          ILE         236   \n",
       "233         233       12AS         0     A          LEU         237   \n",
       "234         234       12AS         0     A          VAL         238   \n",
       "235         235       12AS         0     A          TRP         239   \n",
       "236         236       12AS         0     A          ASN         240   \n",
       "237         237       12AS         0     A          PRO         241   \n",
       "238         238       12AS         0     A          VAL         242   \n",
       "239         239       12AS         0     A          LEU         243   \n",
       "240         240       12AS         0     A          GLU         244   \n",
       "241         241       12AS         0     A          ASP         245   \n",
       "242         242       12AS         0     A          ALA         246   \n",
       "243         243       12AS         0     A          PHE         247   \n",
       "244         244       12AS         0     A          GLU         248   \n",
       "245         245       12AS         0     A          LEU         249   \n",
       "246         246       12AS         0     A          SER         250   \n",
       "247         247       12AS         0     A          SER         251   \n",
       "248         248       12AS         0     A          MET         252   \n",
       "249         249       12AS         0     A          GLY         253   \n",
       "250         250       12AS         0     A          ILE         254   \n",
       "251         251       12AS         0     A          ARG         255   \n",
       "252         252       12AS         0     A          VAL         256   \n",
       "253         253       12AS         0     A          ASP         257   \n",
       "254         254       12AS         0     A          ALA         258   \n",
       "255         255       12AS         0     A          ASP         259   \n",
       "\n",
       "    Amino_Acid Secondary_Structure  Solvent_Accessability    Phi    Psi  \n",
       "0            A                   -               0.896226  360.0  157.9  \n",
       "1            Y                   H               0.090090  -41.6  -56.8  \n",
       "2            I                   H               0.402367  -55.5  -51.1  \n",
       "3            A                   H               0.462264  -54.4  -58.3  \n",
       "4            K                   H               0.112195  -54.3  -39.3  \n",
       "5            Q                   H               0.000000  -61.4  -33.5  \n",
       "6            R                   H               0.508065  -86.1  -32.3  \n",
       "7            Q                   H               0.227273  -52.9  -57.3  \n",
       "8            I                   H               0.000000  -53.8  -50.5  \n",
       "9            S                   H               0.230769  -55.7  -41.7  \n",
       "10           F                   H               0.279188  -64.6  -44.9  \n",
       "11           V                   H               0.000000  -61.1  -54.2  \n",
       "12           K                   H               0.136585  -62.5  -29.9  \n",
       "13           S                   H               0.615385  -80.5  -53.6  \n",
       "14           H                   H               0.168478  -53.4  -50.3  \n",
       "15           F                   H               0.000000  -67.3  -28.8  \n",
       "16           S                   H               0.076923  -57.8  -42.9  \n",
       "17           R                   H               0.524194  -70.4  -32.9  \n",
       "18           Q                   H               0.080808  -59.1  -34.3  \n",
       "19           L                   H               0.018293  -75.1  -35.7  \n",
       "20           E                   H               0.396907  -74.7  -37.6  \n",
       "21           E                   H               0.644330  -87.6  -40.5  \n",
       "22           R                   H               0.463710  -75.4  -28.9  \n",
       "23           L                   H               0.121951 -123.5    0.3  \n",
       "24           G                   -               0.476190   61.8   44.3  \n",
       "25           L                   E               0.024390 -104.2  137.6  \n",
       "26           I                   E               0.201183 -102.2  152.9  \n",
       "27           E                   E               0.262887  -76.6  134.1  \n",
       "28           V                   -               0.014085 -124.3  155.1  \n",
       "29           Q                   -               0.136364  -73.8  129.1  \n",
       "..         ...                 ...                    ...    ...    ...  \n",
       "226          A                   B               0.433962  -80.2  136.6  \n",
       "227          G                   -               0.000000  121.6  132.0  \n",
       "228          L                   S               0.012195 -112.1   35.9  \n",
       "229          N                   E               0.000000 -136.8  174.2  \n",
       "230          G                   E               0.000000  175.6 -172.7  \n",
       "231          D                   E               0.006135 -117.3  152.2  \n",
       "232          I                   E               0.005917  -91.1  128.8  \n",
       "233          L                   E               0.012195 -134.5  135.7  \n",
       "234          V                   E               0.000000 -129.0  165.5  \n",
       "235          W                   E               0.224670  -79.9  116.6  \n",
       "236          N                   E               0.006369  -90.4  111.8  \n",
       "237          P                   T               0.367647  -80.7  -17.1  \n",
       "238          V                   T               0.394366  -75.0  -41.6  \n",
       "239          L                   T               0.286585  -83.1   -8.9  \n",
       "240          E                   T               0.711340   39.0   46.9  \n",
       "241          D                   E               0.417178 -150.5  172.7  \n",
       "242          A                   E               0.150943  -73.9  145.2  \n",
       "243          F                   E               0.005076 -130.7  109.2  \n",
       "244          E                   E               0.298969  -79.1  122.0  \n",
       "245          L                   E               0.054878 -100.0  -32.9  \n",
       "246          S                   E               0.023077 -168.1  154.2  \n",
       "247          S                   E               0.276923 -131.6  126.9  \n",
       "248          M                   E               0.000000 -140.1  179.6  \n",
       "249          G                   E               0.000000  164.8  152.5  \n",
       "250          I                   E               0.000000  -64.1  139.4  \n",
       "251          R                   B               0.028226  -87.3  138.1  \n",
       "252          V                   -               0.000000  -41.1  145.0  \n",
       "253          D                   -               0.343558 -109.2 -171.9  \n",
       "254          A                   H               0.254717  -63.7  -36.8  \n",
       "255          D                   H               0.730061  -80.8  -35.5  \n",
       "\n",
       "[256 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdb_list_y[0].upper() + \".csv\" in os.listdir(\"./ground_truth_cache\")\n",
    "protein_id=pdb_list_y[0]\n",
    "pandas.read_csv(os.path.join(\"ground_truth_cache\",(protein_id.upper() + \".csv\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_map_from_file(pdb_list_y[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max(chip_diagonal(10, 1, 278)[267]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
